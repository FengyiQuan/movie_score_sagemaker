{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to SageMaker ObjectToVec model for MovieLens recommendation\n",
    "\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Data exploration and preparation](#Data-exploration-and-preparation)\n",
    "1. [Rating prediction task](#Rating-prediction-task)\n",
    "1. [Recommendation task](#Recommendation-task)\n",
    "1. [Movie retrieval in the embedding space](#Movie-retrieval-in-the-embedding-space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "### ObjectToVec\n",
    "*Object2Vec* is a highly customizable multi-purpose algorithm that can learn embeddings of pairs of objects. The embeddings are learned such that it preserves their pairwise **similarities** in the original space.\n",
    "- **Similarity** is user-defined: users need to provide the algorithm with pairs of objects that they define as similar (1) or dissimilar (0); alternatively, the users can define similarity in a continuous sense (provide a real-valued similarity score)\n",
    "- The learned embeddings can be used to efficiently compute nearest neighbors of objects, as well as to visualize natural clusters of related objects in the embedding space. In addition, the embeddings can also be used as features of the corresponding objects in downstream supervised tasks such as classification or regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook example:\n",
    "We demonstrate how Object2Vec can be used to solve problems arising in recommendation systems. Specifically,\n",
    "\n",
    "- We provide the algorithm with (UserID, MovieID) pairs; for each such pair, we also provide a \"label\" that tells the algorithm whether the user and movie are similar or not\n",
    "\n",
    "     * When the labels are real-valued, we use the algorithm to predict the exact ratings of a movie given a user\n",
    "     * When the labels are binary, we use the algorithm to recommendation movies to users\n",
    "\n",
    "- The diagram below shows the customization of our model to the problem of predicting movie ratings, using a dataset that provides `(UserID, ItemID, Rating)` samples. Here, ratings are real-valued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:middle\" src=\"image_ml_rating.png\" width=\"480\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "- We use the MovieLens 100k dataset: https://grouplens.org/datasets/movielens/100k/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use cases\n",
    "\n",
    "- Task 1: Rating prediction (regression)\n",
    "- Task 2: Movie recommendation (classification)\n",
    "- Task 3: Nearest-neighbor movie retrieval in the learned embedding space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before running the notebook\n",
    "- Please use a Python 3 kernel for the notebook\n",
    "- Please make sure you have `jsonlines` package installed (if not, you can run the command below to install it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting jsonlines\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonlines) (22.2.0)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv, jsonlines\n",
    "import numpy as np\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "Please be aware of the following requirements about ackonwledgment, copyright and availability, cited from the [data set description page](http://files.grouplens.org/datasets/movielens/ml-100k-README.txt).\n",
    ">The data set may be used for any research\n",
    "purposes under the following conditions:\n",
    "     * The user may not state or imply any endorsement from the\n",
    "       University of Minnesota or the GroupLens Research Group.\n",
    "     * The user must acknowledge the use of the data set in\n",
    "       publications resulting from the use of the data set\n",
    "       (see below for citation information).\n",
    "     * The user may not redistribute the data without separate\n",
    "       permission.\n",
    "     * The user may not use this information for any commercial or\n",
    "       revenue-bearing purposes without first obtaining permission\n",
    "       from a faculty member of the GroupLens Research Project at the\n",
    "       University of Minnesota.\n",
    "If you have any further questions or comments, please contact GroupLens \\<grouplens-info@cs.umn.edu\\>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 4808k  100 4808k    0     0   9.8M      0 --:--:-- --:--:-- --:--:--  9.9M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-100k.zip\n",
      "   creating: ml-100k/\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -o ml-100k.zip http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "unzip ml-100k.zip\n",
    "rm ml-100k.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create some utility functions for data exploration and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some utility functions\n",
    "\n",
    "\n",
    "def load_csv_data(filename, delimiter, verbose=True):\n",
    "    \"\"\"\n",
    "    input: a file readable as csv and separated by a delimiter\n",
    "    and has format users - movies - ratings - etc\n",
    "    output: a list, where each row of the list is of the form\n",
    "    {'in0':userID, 'in1':movieID, 'label':rating}\n",
    "    \"\"\"\n",
    "    to_data_list = list()\n",
    "    users = list()\n",
    "    movies = list()\n",
    "    ratings = list()\n",
    "    unique_users = set()\n",
    "    unique_movies = set()\n",
    "    with open(filename, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=delimiter)\n",
    "        for count, row in enumerate(reader):\n",
    "            # if count!=0:\n",
    "            to_data_list.append(\n",
    "                {\"in0\": [int(row[0])], \"in1\": [int(row[1])], \"label\": float(row[2])}\n",
    "            )\n",
    "            users.append(row[0])\n",
    "            movies.append(row[1])\n",
    "            ratings.append(float(row[2]))\n",
    "            unique_users.add(row[0])\n",
    "            unique_movies.add(row[1])\n",
    "    if verbose:\n",
    "        print(\"In file {}, there are {} ratings\".format(filename, len(ratings)))\n",
    "        print(\n",
    "            \"The ratings have mean: {}, median: {}, and variance: {}\".format(\n",
    "                round(np.mean(ratings), 2), round(np.median(ratings), 2), round(np.var(ratings), 2)\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"There are {} unique users and {} unique movies\".format(\n",
    "                len(unique_users), len(unique_movies)\n",
    "            )\n",
    "        )\n",
    "    return to_data_list\n",
    "\n",
    "\n",
    "def csv_to_augmented_data_dict(filename, delimiter):\n",
    "    \"\"\"\n",
    "    Input: a file that must be readable as csv and separated by delimiter (to make columns)\n",
    "    has format users - movies - ratings - etc\n",
    "    Output:\n",
    "      Users dictionary: keys as user ID's; each key corresponds to a list of movie ratings by that user\n",
    "      Movies dictionary: keys as movie ID's; each key corresponds a list of ratings of that movie by different users\n",
    "    \"\"\"\n",
    "    to_users_dict = dict()\n",
    "    to_movies_dict = dict()\n",
    "    with open(filename, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=delimiter)\n",
    "        for count, row in enumerate(reader):\n",
    "            # if count!=0:\n",
    "            if row[0] not in to_users_dict:\n",
    "                to_users_dict[row[0]] = [(row[1], row[2])]\n",
    "            else:\n",
    "                to_users_dict[row[0]].append((row[1], row[2]))\n",
    "            if row[1] not in to_movies_dict:\n",
    "                to_movies_dict[row[1]] = list(row[0])\n",
    "            else:\n",
    "                to_movies_dict[row[1]].append(row[0])\n",
    "    return to_users_dict, to_movies_dict\n",
    "\n",
    "\n",
    "def user_dict_to_data_list(user_dict):\n",
    "    # turn user_dict format to data list format (acceptable to the algorithm)\n",
    "    data_list = list()\n",
    "    for user, movie_rating_list in user_dict.items():\n",
    "        for movie, rating in movie_rating_list:\n",
    "            data_list.append({\"in0\": [int(user)], \"in1\": [int(movie)], \"label\": float(rating)})\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def divide_user_dicts(user_dict, sp_ratio_dict):\n",
    "    \"\"\"\n",
    "    Input: A user dictionary, a ration dictionary\n",
    "         - format of sp_ratio_dict = {'train':0.8, \"test\":0.2}\n",
    "    Output:\n",
    "        A dictionary of dictionaries, with key corresponding to key provided by sp_ratio_dict\n",
    "        and each key corresponds to a subdivded user dictionary\n",
    "    \"\"\"\n",
    "    ratios = [val for _, val in sp_ratio_dict.items()]\n",
    "    assert np.sum(ratios) == 1, \"the sampling ratios must sum to 1!\"\n",
    "    divided_dict = {}\n",
    "    for user, movie_rating_list in user_dict.items():\n",
    "        sub_movies_ptr = 0\n",
    "        sub_movies_list = []\n",
    "        # movie_list, _ = zip(*movie_rating_list)\n",
    "        # print(movie_list)\n",
    "        for i, ratio in enumerate(ratios):\n",
    "            if i < len(ratios) - 1:\n",
    "                sub_movies_ptr_end = sub_movies_ptr + int(len(movie_rating_list) * ratio)\n",
    "                sub_movies_list.append(movie_rating_list[sub_movies_ptr:sub_movies_ptr_end])\n",
    "                sub_movies_ptr = sub_movies_ptr_end\n",
    "            else:\n",
    "                sub_movies_list.append(movie_rating_list[sub_movies_ptr:])\n",
    "        for subset_name in sp_ratio_dict.keys():\n",
    "            if subset_name not in divided_dict:\n",
    "                divided_dict[subset_name] = {user: sub_movies_list.pop(0)}\n",
    "            else:\n",
    "                # access sub-dictionary\n",
    "                divided_dict[subset_name][user] = sub_movies_list.pop(0)\n",
    "\n",
    "    return divided_dict\n",
    "\n",
    "\n",
    "def write_csv_to_jsonl(jsonl_fname, csv_fname, csv_delimiter):\n",
    "    \"\"\"\n",
    "    Input: a file readable as csv and separated by delimiter (to make columns)\n",
    "        - has format users - movies - ratings - etc\n",
    "    Output: a jsonline file converted from the csv file\n",
    "    \"\"\"\n",
    "    with jsonlines.open(jsonl_fname, mode=\"w\") as writer:\n",
    "        with open(csv_fname, \"r\") as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=csv_delimiter)\n",
    "            for count, row in enumerate(reader):\n",
    "                # print(row)\n",
    "                # if count!=0:\n",
    "                writer.write({\"in0\": [int(row[0])], \"in1\": [int(row[1])], \"label\": float(row[2])})\n",
    "        print(\"Created {} jsonline file\".format(jsonl_fname))\n",
    "\n",
    "\n",
    "def write_data_list_to_jsonl(data_list, to_fname):\n",
    "    \"\"\"\n",
    "    Input: a data list, where each row of the list is a Python dictionary taking form\n",
    "    {'in0':userID, 'in1':movieID, 'label':rating}\n",
    "    Output: save the list as a jsonline file\n",
    "    \"\"\"\n",
    "    with jsonlines.open(to_fname, mode=\"w\") as writer:\n",
    "        for row in data_list:\n",
    "            # print(row)\n",
    "            writer.write({\"in0\": row[\"in0\"], \"in1\": row[\"in1\"], \"label\": row[\"label\"]})\n",
    "    print(\"Created {} jsonline file\".format(to_fname))\n",
    "\n",
    "\n",
    "def data_list_to_inference_format(data_list, binarize=True, label_thres=3):\n",
    "    \"\"\"\n",
    "    Input: a data list\n",
    "    Output: test data and label, acceptable by SageMaker for inference\n",
    "    \"\"\"\n",
    "    data_ = [({\"in0\": row[\"in0\"], \"in1\": row[\"in1\"]}, row[\"label\"]) for row in data_list]\n",
    "    data, label = zip(*data_)\n",
    "    infer_data = {\"instances\": data}\n",
    "    if binarize:\n",
    "        label = get_binarized_label(list(label), label_thres)\n",
    "    return infer_data, label\n",
    "\n",
    "\n",
    "def get_binarized_label(data_list, thres):\n",
    "    \"\"\"\n",
    "    Input: data list\n",
    "    Output: a binarized data list for recommendation task\n",
    "    \"\"\"\n",
    "    for i, row in enumerate(data_list):\n",
    "        if type(row) is dict:\n",
    "            # if i < 10:\n",
    "            # print(row['label'])\n",
    "            if row[\"label\"] > thres:\n",
    "                # print(row)\n",
    "                data_list[i][\"label\"] = 1\n",
    "            else:\n",
    "                data_list[i][\"label\"] = 0\n",
    "        else:\n",
    "            if row > thres:\n",
    "                data_list[i] = 1\n",
    "            else:\n",
    "                data_list[i] = 0\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file ml-100k/ua.base, there are 90570 ratings\n",
      "The ratings have mean: 3.52, median: 4.0, and variance: 1.27\n",
      "There are 943 unique users and 1680 unique movies\n",
      "In file ml-100k/ua.test, there are 9430 ratings\n",
      "The ratings have mean: 3.59, median: 4.0, and variance: 1.25\n",
      "There are 943 unique users and 1129 unique movies\n"
     ]
    }
   ],
   "source": [
    "## Load data and shuffle\n",
    "prefix = \"ml-100k\"\n",
    "train_path = os.path.join(prefix, \"ua.base\")\n",
    "valid_path = os.path.join(prefix, \"ua.test\")\n",
    "test_path = os.path.join(prefix, \"ub.test\")\n",
    "\n",
    "train_data_list = load_csv_data(train_path, \"\\t\")\n",
    "random.shuffle(train_data_list)\n",
    "validation_data_list = load_csv_data(valid_path, \"\\t\")\n",
    "random.shuffle(validation_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_users_dict, to_movies_dict = csv_to_augmented_data_dict(train_path, \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We perform some data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min, max, and median 'movies per user' is 10, 727, and 55.0\n",
      "The min, max, and median 'users per movie' is 1, 495, and 25.0\n",
      "In the training set\n",
      "There are 213 users with no more than 20 movies\n",
      "There are 12 movies with no more than 2 user\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Users per movie')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Calculate min, max, median of number of movies per user\n",
    "movies_per_user = [len(val) for key, val in to_users_dict.items()]\n",
    "\n",
    "print(\n",
    "    \"The min, max, and median 'movies per user' is {}, {}, and {}\".format(\n",
    "        np.amin(movies_per_user), np.amax(movies_per_user), np.median(movies_per_user)\n",
    "    )\n",
    ")\n",
    "users_per_movie = [len(val) for key, val in to_movies_dict.items()]\n",
    "print(\n",
    "    \"The min, max, and median 'users per movie' is {}, {}, and {}\".format(\n",
    "        np.amin(users_per_movie), np.amax(users_per_movie), np.median(users_per_movie)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "count = 0\n",
    "n_movies_lower_bound = 20\n",
    "for n_movies in movies_per_user:\n",
    "    if n_movies <= n_movies_lower_bound:\n",
    "        count += 1\n",
    "print(\"In the training set\")\n",
    "print(\"There are {} users with no more than {} movies\".format(count, n_movies_lower_bound))\n",
    "#\n",
    "count = 0\n",
    "n_users_lower_bound = 2\n",
    "for n_users in users_per_movie:\n",
    "    if n_users <= n_users_lower_bound:\n",
    "        count += 1\n",
    "print(\"There are {} movies with no more than {} user\".format(count, n_users_lower_bound))\n",
    "\n",
    "\n",
    "## figures\n",
    "\n",
    "f = plt.figure(1)\n",
    "plt.hist(movies_per_user)\n",
    "plt.title(\"Movies per user\")\n",
    "##\n",
    "g = plt.figure(2)\n",
    "plt.hist(users_per_movie)\n",
    "plt.title(\"Users per movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of movies with an extremely small number of users (<3) is negligible compared to the total number of movies, we will not remove movies from the data set (same applies for users) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train_r.jsonl jsonline file\n",
      "Created validation_r.jsonl jsonline file\n"
     ]
    }
   ],
   "source": [
    "## Save training and validation data locally for rating-prediction (regression) task\n",
    "\n",
    "write_data_list_to_jsonl(copy.deepcopy(train_data_list), \"train_r.jsonl\")\n",
    "write_data_list_to_jsonl(copy.deepcopy(validation_data_list), \"validation_r.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train_c.jsonl jsonline file\n",
      "Created validation_c.jsonl jsonline file\n"
     ]
    }
   ],
   "source": [
    "## Save training and validation data locally for recommendation (classification) task\n",
    "\n",
    "### binarize the data\n",
    "\n",
    "train_c = get_binarized_label(copy.deepcopy(train_data_list), 3.0)\n",
    "valid_c = get_binarized_label(copy.deepcopy(validation_data_list), 3.0)\n",
    "\n",
    "write_data_list_to_jsonl(train_c, \"train_c.jsonl\")\n",
    "write_data_list_to_jsonl(valid_c, \"validation_c.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We check whether the two classes are balanced after binarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0.5510213094843768 fraction of positive ratings in train_c.jsonl\n",
      "There are 0.5799575821845175 fraction of positive ratings in validation_c.jsonl\n"
     ]
    }
   ],
   "source": [
    "train_c_label = [row[\"label\"] for row in train_c]\n",
    "valid_c_label = [row[\"label\"] for row in valid_c]\n",
    "\n",
    "print(\n",
    "    \"There are {} fraction of positive ratings in train_c.jsonl\".format(\n",
    "        np.count_nonzero(train_c_label) / len(train_c_label)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"There are {} fraction of positive ratings in validation_c.jsonl\".format(\n",
    "        np.sum(valid_c_label) / len(valid_c_label)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating prediction task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse_loss(res, labels):\n",
    "    if type(res) is dict:\n",
    "        res = res[\"predictions\"]\n",
    "    assert len(res) == len(labels), \"result and label length mismatch!\"\n",
    "    loss = 0\n",
    "    for row, label in zip(res, labels):\n",
    "        if type(row) is dict:\n",
    "            loss += (row[\"scores\"][0] - label) ** 2\n",
    "        else:\n",
    "            loss += (row - label) ** 2\n",
    "    return round(loss / float(len(labels)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_r_data, valid_r_label = data_list_to_inference_format(\n",
    "    copy.deepcopy(validation_data_list), binarize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We first test the problem on two baseline algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 1\n",
    "\n",
    "A naive approach to predict movie ratings on unseen data is to use the global average of the user predictions in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Baseline 1 (global rating average) prediction is 3.52\n",
      "The validation mse loss of the Baseline 1 is 1.26\n"
     ]
    }
   ],
   "source": [
    "train_r_label = [row[\"label\"] for row in copy.deepcopy(train_data_list)]\n",
    "\n",
    "bs1_prediction = round(np.mean(train_r_label), 2)\n",
    "print(\"The Baseline 1 (global rating average) prediction is {}\".format(bs1_prediction))\n",
    "print(\n",
    "    \"The validation mse loss of the Baseline 1 is {}\".format(\n",
    "        get_mse_loss(len(valid_r_label) * [bs1_prediction], valid_r_label)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use a better baseline, which is to perform prediction on unseen data based on the user-averaged ratings of movies on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bs2_predictor(test_data, user_dict, is_classification=False, thres=3):\n",
    "    test_data = copy.deepcopy(test_data[\"instances\"])\n",
    "    predictions = list()\n",
    "    for row in test_data:\n",
    "        userID = str(row[\"in0\"][0])\n",
    "        # predict movie ID based on local average of user's prediction\n",
    "        local_movies, local_ratings = zip(*user_dict[userID])\n",
    "        local_ratings = [float(score) for score in local_ratings]\n",
    "        predictions.append(np.mean(local_ratings))\n",
    "        if is_classification:\n",
    "            predictions[-1] = int(predictions[-1] > 3)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss of the Baseline 2 (user-based rating average) is 1.09\n"
     ]
    }
   ],
   "source": [
    "bs2_prediction = bs2_predictor(valid_r_data, to_users_dict, is_classification=False)\n",
    "print(\n",
    "    \"The validation loss of the Baseline 2 (user-based rating average) is {}\".format(\n",
    "        get_mse_loss(bs2_prediction, valid_r_label)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use *Object2Vec* to predict the movie ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define S3 bucket that hosts data and model, and upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "\n",
    "bucket = sagemaker.session.Session().default_bucket()\n",
    "input_prefix = \"object2vec/movielens/input\"\n",
    "output_prefix = \"object2vec/movielens/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Upload data to S3 and make data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded train data to s3://sagemaker-us-east-1-112573511757/object2vec/movielens/input/rating/train/train_r.jsonl and defined input path\n",
      "Uploaded validation data to s3://sagemaker-us-east-1-112573511757/object2vec/movielens/input/rating/validation/validation_r.jsonl and defined input path\n",
      "Trained model will be saved at s3://sagemaker-us-east-1-112573511757/object2vec/movielens/output\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "input_paths = {}\n",
    "output_path = os.path.join(\"s3://\", bucket, output_prefix)\n",
    "\n",
    "for data_name in [\"train\", \"validation\"]:\n",
    "    pre_key = os.path.join(input_prefix, \"rating\", f\"{data_name}\")\n",
    "    fname = \"{}_r.jsonl\".format(data_name)\n",
    "    data_path = os.path.join(\"s3://\", bucket, pre_key, fname)\n",
    "    s3_client.upload_file(fname, bucket, os.path.join(pre_key, fname))\n",
    "    input_paths[data_name] = TrainingInput(\n",
    "        data_path, distribution=\"ShardedByS3Key\", content_type=\"application/jsonlines\"\n",
    "    )\n",
    "    print(\"Uploaded {} data to {} and defined input path\".format(data_name, data_path))\n",
    "\n",
    "print(\"Trained model will be saved at\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get ObjectToVec algorithm image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::112573511757:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "## Get docker image of ObjectToVec algorithm\n",
    "from sagemaker import image_uris\n",
    "\n",
    "container = image_uris.retrieve(region=boto3.Session().region_name, framework=\"object2vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We first define training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"_kvstore\": \"device\",\n",
    "    \"_num_gpus\": \"auto\",\n",
    "    \"_num_kv_servers\": \"auto\",\n",
    "    \"bucket_width\": 0,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_tolerance\": 0.01,\n",
    "    \"enc0_cnn_filter_width\": 3,\n",
    "    \"enc0_layers\": \"auto\",\n",
    "    \"enc0_max_seq_len\": 1,\n",
    "    \"enc0_network\": \"pooled_embedding\",\n",
    "    \"enc0_token_embedding_dim\": 300,\n",
    "    \"enc0_vocab_size\": 944,\n",
    "    \"enc1_layers\": \"auto\",\n",
    "    \"enc1_max_seq_len\": 1,\n",
    "    \"enc1_network\": \"pooled_embedding\",\n",
    "    \"enc1_token_embedding_dim\": 300,\n",
    "    \"enc1_vocab_size\": 1684,\n",
    "    \"enc_dim\": 1024,\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"mini_batch_size\": 64,\n",
    "    \"mlp_activation\": \"tanh\",\n",
    "    \"mlp_dim\": 256,\n",
    "    \"mlp_layers\": 1,\n",
    "    \"num_classes\": 2,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"output_layer\": \"mean_squared_error\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: object2vec-2023-04-30-05-58-21-528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-30 05:58:21 Starting - Starting the training job...\n",
      "2023-04-30 05:58:48 Starting - Preparing the instances for training.........\n",
      "2023-04-30 06:00:16 Downloading - Downloading input data...\n",
      "2023-04-30 06:00:51 Training - Downloading the training image..................\n",
      "2023-04-30 06:03:27 Training - Training image download completed. Training in progress...\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mNvidia gpu devices, drivers and cuda toolkit versions (only available on hosts with GPU):\u001b[0m\n",
      "\u001b[34mSun Apr 30 06:04:03 2023       \u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34m| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\u001b[0m\n",
      "\u001b[34m|-------------------------------+----------------------+----------------------+\u001b[0m\n",
      "\u001b[34m| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\u001b[0m\n",
      "\u001b[34m| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\u001b[0m\n",
      "\u001b[34m|                               |                      |               MIG M. |\u001b[0m\n",
      "\u001b[34m|===============================+======================+======================|\u001b[0m\n",
      "\u001b[34m|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\u001b[0m\n",
      "\u001b[34m| N/A   29C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\u001b[0m\n",
      "\u001b[34m|                               |                      |                  N/A |\u001b[0m\n",
      "\u001b[34m+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34m| Processes:                                                                  |\u001b[0m\n",
      "\u001b[34m|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\u001b[0m\n",
      "\u001b[34m|        ID   ID                                                   Usage      |\u001b[0m\n",
      "\u001b[34m|=============================================================================|\u001b[0m\n",
      "\u001b[34m|  No running processes found                                                 |\u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34mChecking for nvidia driver and cuda compatibility.\u001b[0m\n",
      "\u001b[34mCUDA Compatibility driver provided.\u001b[0m\n",
      "\u001b[34mProceeding with compatibility check between driver, cuda-toolkit and cuda-compat.\u001b[0m\n",
      "\u001b[34mDetected cuda-toolkit version: 11.1.\u001b[0m\n",
      "\u001b[34mDetected cuda-compat version: 455.32.00.\u001b[0m\n",
      "\u001b[34mDetected Nvidia driver version: 470.57.02.\u001b[0m\n",
      "\u001b[34mNvidia driver compatible with cuda-toolkit. Disabling cuda-compat.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/default-input.json: {'enc_dim': 4096, 'mlp_dim': 512, 'mlp_activation': 'linear', 'mlp_layers': 2, 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': 0.0004, 'mini_batch_size': 32, 'epochs': 30, 'bucket_width': 0, 'early_stopping_tolerance': 0.01, 'early_stopping_patience': 3, 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'hcnn', 'enc1_network': 'enc0', 'enc0_token_embedding_dim': 300, 'enc0_layers': 'auto', 'enc0_cnn_filter_width': 3, 'enc1_token_embedding_dim': 300, 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': 2, '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'auto_gpu'}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'_kvstore': 'device', '_num_gpus': 'auto', '_num_kv_servers': 'auto', 'bucket_width': '0', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.01', 'enc0_cnn_filter_width': '3', 'enc0_layers': 'auto', 'enc0_max_seq_len': '1', 'enc0_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_vocab_size': '944', 'enc1_layers': 'auto', 'enc1_max_seq_len': '1', 'enc1_network': 'pooled_embedding', 'enc1_token_embedding_dim': '300', 'enc1_vocab_size': '1684', 'enc_dim': '1024', 'epochs': '20', 'learning_rate': '0.001', 'mini_batch_size': '64', 'mlp_activation': 'tanh', 'mlp_dim': '256', 'mlp_layers': '1', 'num_classes': '2', 'optimizer': 'adam', 'output_layer': 'mean_squared_error'}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] Final configuration: {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc0_max_seq_len': '1', 'enc0_vocab_size': '944', 'enc1_max_seq_len': '1', 'enc1_vocab_size': '1684'}\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] Using default worker.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] Loaded iterator creator application/jsonlines for content type ('application/jsonlines', '1.0')\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] create_iter params {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc0_max_seq_len': '1', 'enc0_vocab_size': '944', 'enc1_max_seq_len': '1', 'enc1_vocab_size': '1684'}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] Parameters of encoders: [{'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '944'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': 3, 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '1684'}]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] Config: {'enc_dim': 1024, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'mlp_dim': 256, 'mlp_layers': 1, 'output_layer': 'mean_squared_error', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': None, 'epochs': 20, 'mini_batch_size': 64, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] use bucketing: False\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:08 INFO 139898075215680] Creating data iterator for /opt/ml/input/data/train\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Source words: 90570\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Target words: 90570\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Total: 90570 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Bucket of (1, 1) : 90570 samples in 1416 batches of 64, approx 64.0 words/batch\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Replicating 54 random sentences from bucket (1, 1) to size it to multiple of 64\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Bucket batch sizes: [BucketBatchSize(batch_size=64, average_words_per_batch=64.0)]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] create_iter params {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc0_max_seq_len': '1', 'enc0_vocab_size': '944', 'enc1_max_seq_len': '1', 'enc1_vocab_size': '1684'}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Parameters of encoders: [{'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '944'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': 3, 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '1684'}]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Config: {'enc_dim': 1024, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'mlp_dim': 256, 'mlp_layers': 1, 'output_layer': 'mean_squared_error', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': None, 'epochs': 20, 'mini_batch_size': 64, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] use bucketing: False\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Creating data iterator for /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Source words: 9430\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Target words: 9430\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Total: 9430 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Bucket of (1, 1) : 9430 samples in 148 batches of 64, approx 64.0 words/batch\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Replicating 42 random sentences from bucket (1, 1) to size it to multiple of 64\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Parameters of encoders: [{'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '944'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': 3, 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '1684'}]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Config: {'enc_dim': 1024, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'mlp_dim': 256, 'mlp_layers': 1, 'output_layer': 'mean_squared_error', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': None, 'epochs': 20, 'mini_batch_size': 64, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Creating new state\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] params {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc0_max_seq_len': '1', 'enc0_vocab_size': '944', 'enc1_max_seq_len': '1', 'enc1_vocab_size': '1684', 'default_bucket_key': (1, 1)}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] default_bucket_key (1, 1)\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] nvidia-smi: took 0.034 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] nvidia-smi identified 1 GPUs.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] context [gpu(0)]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Create Store: device\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 WARNING 139898075215680] dense token embedding is used in a multi-gpu setting...consider changing 'token_embedding_storage_type' to 'row_sparse'\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] data_names: ['source', 'target']\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] label_names: ['out_layer_label']\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                                        Output Shape            Param #     Previous Layer                  \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34msource(null)                                        1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_0(Embedding)                                  1x1024                  0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar0(_not_equal_scalar)               1                       0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape0(Reshape)                                   1x1                     0           _not_equal_scalar0              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul0(broadcast_mul)                       1x1024                  0           embed_0                         \n",
      "                                                                                        reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum0(sum)                                           1024                    0           broadcast_mul0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum1(sum)                                           1                       0           reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like0(zeros_like)                             1                       0           sum1                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal0(_equal)                                     1                       0           sum1                            \n",
      "                                                                                        zeros_like0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus0(elemwise_add)                                1                       0           sum1                            \n",
      "                                                                                        _equal0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div0(broadcast_div)                       1024                    0           sum0                            \n",
      "                                                                                        _plus0                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout0(Dropout)                                   1024                    0           broadcast_div0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_1(Embedding)                                  1x1024                  0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar1(_not_equal_scalar)               1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape1(Reshape)                                   1x1                     0           _not_equal_scalar1              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul1(broadcast_mul)                       1x1024                  0           embed_1                         \n",
      "                                                                                        reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum2(sum)                                           1024                    0           broadcast_mul1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum3(sum)                                           1                       0           reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like1(zeros_like)                             1                       0           sum3                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal1(_equal)                                     1                       0           sum3                            \n",
      "                                                                                        zeros_like1                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus1(elemwise_add)                                1                       0           sum3                            \n",
      "                                                                                        _equal1                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div1(broadcast_div)                       1024                    0           sum2                            \n",
      "                                                                                        _plus1                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout1(Dropout)                                   1024                    0           broadcast_div1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_mul0(elemwise_mul)                                 1024                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_minus0(elemwise_sub)                               1024                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mabs0(abs)                                           1024                    0           _minus0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcat0(Concat)                                     4096                    0           _mul0                           \n",
      "                                                                                        dropout0                        \n",
      "                                                                                        dropout1                        \n",
      "                                                                                        abs0                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmlp_fc0(FullyConnected)                             256                     1048832     concat0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation0(Activation)                             256                     0           mlp_fc0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout2(Dropout)                                   256                     0           activation0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34moutput_layer(FullyConnected)                        1                       257         dropout2                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mout_layer(LinearRegressionOutput)                   1                       0           output_layer                    \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 1049089\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] data_shapes [DataDesc[source,(64, 1),<class 'numpy.float32'>,NTC], DataDesc[target,(64, 1),<class 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] label_shapes [DataDesc[out_layer_label,(64,),<class 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] fixed_param_names: []\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:11 INFO 139898075215680] Initialized BucketingPlus Module\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:14 INFO 139898075215680] arg_params keys for module initialization: dict_keys([])\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:14 INFO 139898075215680] all params:dict_keys(['embed_0_weight', 'embed_1_weight', 'mlp_fc0_weight', 'mlp_fc0_bias', 'output_layer_weight', 'output_layer_bias'])\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834648.2856112, \"EndTime\": 1682834654.4898214, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 3042.1900749206543, \"count\": 1, \"min\": 3042.1900749206543, \"max\": 3042.1900749206543}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834654.4899857, \"EndTime\": 1682834654.4900427, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:14 INFO 139898075215680] Epoch: 0, batches: 100, num_examples: 6400, 15602.4 samples/sec, epoch time so far: 0:00:00.410192\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:14 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.579 mean_absolute_error: 0.981 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:15 INFO 139898075215680] Epoch: 0, batches: 200, num_examples: 12800, 15781.2 samples/sec, epoch time so far: 0:00:00.811090\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:15 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.327 mean_absolute_error: 0.904 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:15 INFO 139898075215680] Epoch: 0, batches: 300, num_examples: 19200, 15873.1 samples/sec, epoch time so far: 0:00:01.209597\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:15 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.235 mean_absolute_error: 0.875 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:16 INFO 139898075215680] Epoch: 0, batches: 400, num_examples: 25600, 15891.0 samples/sec, epoch time so far: 0:00:01.610974\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:16 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.186 mean_absolute_error: 0.859 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:16 INFO 139898075215680] Epoch: 0, batches: 500, num_examples: 32000, 15898.0 samples/sec, epoch time so far: 0:00:02.012834\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:16 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.154 mean_absolute_error: 0.849 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:16 INFO 139898075215680] Epoch: 0, batches: 600, num_examples: 38400, 15906.7 samples/sec, epoch time so far: 0:00:02.414078\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:16 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.123 mean_absolute_error: 0.837 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:17 INFO 139898075215680] Epoch: 0, batches: 700, num_examples: 44800, 15907.0 samples/sec, epoch time so far: 0:00:02.816376\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:17 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.097 mean_absolute_error: 0.827 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:17 INFO 139898075215680] Epoch: 0, batches: 800, num_examples: 51200, 15887.8 samples/sec, epoch time so far: 0:00:03.222608\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:17 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.082 mean_absolute_error: 0.822 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:18 INFO 139898075215680] Epoch: 0, batches: 900, num_examples: 57600, 15895.0 samples/sec, epoch time so far: 0:00:03.623774\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:18 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.069 mean_absolute_error: 0.817 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:18 INFO 139898075215680] Epoch: 0, batches: 1000, num_examples: 64000, 15890.7 samples/sec, epoch time so far: 0:00:04.027507\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:18 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.057 mean_absolute_error: 0.813 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:19 INFO 139898075215680] Epoch: 0, batches: 1100, num_examples: 70400, 15900.6 samples/sec, epoch time so far: 0:00:04.427519\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:19 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.046 mean_absolute_error: 0.809 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:19 INFO 139898075215680] Epoch: 0, batches: 1200, num_examples: 76800, 15899.0 samples/sec, epoch time so far: 0:00:04.830492\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:19 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.034 mean_absolute_error: 0.804 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:19 INFO 139898075215680] Epoch: 0, batches: 1300, num_examples: 83200, 15910.3 samples/sec, epoch time so far: 0:00:05.229317\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:19 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.025 mean_absolute_error: 0.801 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:20 INFO 139898075215680] Epoch: 0, batches: 1400, num_examples: 89600, 15915.4 samples/sec, epoch time so far: 0:00:05.629752\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:20 INFO 139898075215680] #011Training metrics: mean_squared_error: 1.017 mean_absolute_error: 0.798 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:20 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:20 INFO 139898075215680] Completed Epoch: 0, time taken: 0:00:05.694785\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:20 INFO 139898075215680] Epoch 0 Training metrics:   mean_squared_error: 1.017 mean_absolute_error: 0.798 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:20 INFO 139898075215680] #quality_metric: host=algo-1, epoch=0, train mean_squared_error <loss>=1.0165777435831431\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:20 INFO 139898075215680] Epoch 0 Validation metrics: mean_squared_error: 0.951 mean_absolute_error: 0.779 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:20 INFO 139898075215680] #quality_metric: host=algo-1, epoch=0, validation mean_squared_error <loss>=0.95061389940816\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:20 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834654.4899285, \"EndTime\": 1682834660.4694006, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"early_stop.time\": {\"sum\": 0.7958412170410156, \"count\": 1, \"min\": 0.7958412170410156, \"max\": 0.7958412170410156}, \"update.time\": {\"sum\": 5895.88475227356, \"count\": 1, \"min\": 5895.88475227356, \"max\": 5895.88475227356}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:20 INFO 139898075215680] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834654.5734882, \"EndTime\": 1682834660.4697516, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Total Batches Seen\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:20 INFO 139898075215680] #throughput_metric: host=algo-1, train throughput=15369.238165112301 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:20 INFO 139898075215680] Epoch: 1, batches: 100, num_examples: 6400, 15987.2 samples/sec, epoch time so far: 0:00:00.400321\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:20 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.723 mean_absolute_error: 0.665 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:21 INFO 139898075215680] Epoch: 1, batches: 200, num_examples: 12800, 16003.7 samples/sec, epoch time so far: 0:00:00.799815\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:21 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.717 mean_absolute_error: 0.666 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:21 INFO 139898075215680] Epoch: 1, batches: 300, num_examples: 19200, 15537.3 samples/sec, epoch time so far: 0:00:01.235739\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:21 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.714 mean_absolute_error: 0.664 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:22 INFO 139898075215680] Epoch: 1, batches: 400, num_examples: 25600, 15527.0 samples/sec, epoch time so far: 0:00:01.648741\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:22 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.715 mean_absolute_error: 0.665 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:22 INFO 139898075215680] Epoch: 1, batches: 500, num_examples: 32000, 15333.4 samples/sec, epoch time so far: 0:00:02.086941\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:22 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.706 mean_absolute_error: 0.661 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:22 INFO 139898075215680] Epoch: 1, batches: 600, num_examples: 38400, 15388.9 samples/sec, epoch time so far: 0:00:02.495306\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:22 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.698 mean_absolute_error: 0.657 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:23 INFO 139898075215680] Epoch: 1, batches: 700, num_examples: 44800, 15242.7 samples/sec, epoch time so far: 0:00:02.939111\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:23 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.693 mean_absolute_error: 0.654 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:23 INFO 139898075215680] Epoch: 1, batches: 800, num_examples: 51200, 15266.4 samples/sec, epoch time so far: 0:00:03.353778\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:23 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.682 mean_absolute_error: 0.649 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:24 INFO 139898075215680] Epoch: 1, batches: 900, num_examples: 57600, 15348.9 samples/sec, epoch time so far: 0:00:03.752702\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:24 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.675 mean_absolute_error: 0.645 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:24 INFO 139898075215680] Epoch: 1, batches: 1000, num_examples: 64000, 15411.8 samples/sec, epoch time so far: 0:00:04.152659\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:24 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.669 mean_absolute_error: 0.642 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:25 INFO 139898075215680] Epoch: 1, batches: 1100, num_examples: 70400, 15461.7 samples/sec, epoch time so far: 0:00:04.553196\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:25 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.668 mean_absolute_error: 0.642 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:25 INFO 139898075215680] Epoch: 1, batches: 1200, num_examples: 76800, 15504.6 samples/sec, epoch time so far: 0:00:04.953372\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:25 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.665 mean_absolute_error: 0.640 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:25 INFO 139898075215680] Epoch: 1, batches: 1300, num_examples: 83200, 15537.7 samples/sec, epoch time so far: 0:00:05.354710\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:25 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.661 mean_absolute_error: 0.638 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/30/2023 06:04:26 INFO 139898075215680] Epoch: 1, batches: 1400, num_examples: 89600, 15568.0 samples/sec, epoch time so far: 0:00:05.755382\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:26 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.657 mean_absolute_error: 0.636 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:26 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:26 INFO 139898075215680] Completed Epoch: 1, time taken: 0:00:05.820229\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:26 INFO 139898075215680] Epoch 1 Training metrics:   mean_squared_error: 0.657 mean_absolute_error: 0.636 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:26 INFO 139898075215680] #quality_metric: host=algo-1, epoch=1, train mean_squared_error <loss>=0.6571636071986398\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:26 INFO 139898075215680] Epoch 1 Validation metrics: mean_squared_error: 0.963 mean_absolute_error: 0.782 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:26 INFO 139898075215680] #quality_metric: host=algo-1, epoch=1, validation mean_squared_error <loss>=0.963320367239617\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:26 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834660.4695008, \"EndTime\": 1682834666.516747, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.0286102294921875, \"count\": 1, \"min\": 0.0286102294921875, \"max\": 0.0286102294921875}, \"update.time\": {\"sum\": 6013.338565826416, \"count\": 1, \"min\": 6013.338565826416, \"max\": 6013.338565826416}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:26 INFO 139898075215680] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834660.5033896, \"EndTime\": 1682834666.5170412, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 181248.0, \"count\": 1, \"min\": 181248, \"max\": 181248}, \"Total Batches Seen\": {\"sum\": 2832.0, \"count\": 1, \"min\": 2832, \"max\": 2832}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:26 INFO 139898075215680] #throughput_metric: host=algo-1, train throughput=15069.254126392283 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:26 INFO 139898075215680] Epoch: 2, batches: 100, num_examples: 6400, 15868.2 samples/sec, epoch time so far: 0:00:00.403322\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:26 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.270 mean_absolute_error: 0.397 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:27 INFO 139898075215680] Epoch: 2, batches: 200, num_examples: 12800, 15934.8 samples/sec, epoch time so far: 0:00:00.803272\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:27 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.274 mean_absolute_error: 0.399 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:27 INFO 139898075215680] Epoch: 2, batches: 300, num_examples: 19200, 15939.1 samples/sec, epoch time so far: 0:00:01.204582\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:27 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.271 mean_absolute_error: 0.396 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:28 INFO 139898075215680] Epoch: 2, batches: 400, num_examples: 25600, 15968.7 samples/sec, epoch time so far: 0:00:01.603139\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:28 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.268 mean_absolute_error: 0.394 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:28 INFO 139898075215680] Epoch: 2, batches: 500, num_examples: 32000, 15952.5 samples/sec, epoch time so far: 0:00:02.005955\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:28 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.265 mean_absolute_error: 0.393 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:28 INFO 139898075215680] Epoch: 2, batches: 600, num_examples: 38400, 15919.4 samples/sec, epoch time so far: 0:00:02.412145\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:28 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.264 mean_absolute_error: 0.393 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:29 INFO 139898075215680] Epoch: 2, batches: 700, num_examples: 44800, 15937.4 samples/sec, epoch time so far: 0:00:02.811000\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:29 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.265 mean_absolute_error: 0.394 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:29 INFO 139898075215680] Epoch: 2, batches: 800, num_examples: 51200, 15936.8 samples/sec, epoch time so far: 0:00:03.212689\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:29 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.265 mean_absolute_error: 0.394 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:30 INFO 139898075215680] Epoch: 2, batches: 900, num_examples: 57600, 15928.8 samples/sec, epoch time so far: 0:00:03.616083\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:30 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.267 mean_absolute_error: 0.396 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:30 INFO 139898075215680] Epoch: 2, batches: 1000, num_examples: 64000, 15935.9 samples/sec, epoch time so far: 0:00:04.016082\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:30 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.268 mean_absolute_error: 0.397 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:30 INFO 139898075215680] Epoch: 2, batches: 1100, num_examples: 70400, 15944.4 samples/sec, epoch time so far: 0:00:04.415350\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:30 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.269 mean_absolute_error: 0.398 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:31 INFO 139898075215680] Epoch: 2, batches: 1200, num_examples: 76800, 15941.6 samples/sec, epoch time so far: 0:00:04.817584\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:31 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.270 mean_absolute_error: 0.399 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:31 INFO 139898075215680] Epoch: 2, batches: 1300, num_examples: 83200, 15932.8 samples/sec, epoch time so far: 0:00:05.221921\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:31 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.272 mean_absolute_error: 0.400 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:32 INFO 139898075215680] Epoch: 2, batches: 1400, num_examples: 89600, 15932.6 samples/sec, epoch time so far: 0:00:05.623689\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:32 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.273 mean_absolute_error: 0.401 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:32 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:32 INFO 139898075215680] Completed Epoch: 2, time taken: 0:00:05.692104\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:32 INFO 139898075215680] Epoch 2 Training metrics:   mean_squared_error: 0.272 mean_absolute_error: 0.401 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:32 INFO 139898075215680] #quality_metric: host=algo-1, epoch=2, train mean_squared_error <loss>=0.2724962282168158\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:32 INFO 139898075215680] Epoch 2 Validation metrics: mean_squared_error: 0.945 mean_absolute_error: 0.767 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:32 INFO 139898075215680] #quality_metric: host=algo-1, epoch=2, validation mean_squared_error <loss>=0.9449727354017464\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:32 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834666.5168486, \"EndTime\": 1682834672.4150035, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 2.60162353515625, \"count\": 1, \"min\": 2.60162353515625, \"max\": 2.60162353515625}, \"update.time\": {\"sum\": 5891.201734542847, \"count\": 1, \"min\": 5891.201734542847, \"max\": 5891.201734542847}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:32 INFO 139898075215680] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834666.523787, \"EndTime\": 1682834672.4153795, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 271872.0, \"count\": 1, \"min\": 271872, \"max\": 271872}, \"Total Batches Seen\": {\"sum\": 4248.0, \"count\": 1, \"min\": 4248, \"max\": 4248}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:32 INFO 139898075215680] #throughput_metric: host=algo-1, train throughput=15381.467328718652 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:32 INFO 139898075215680] Epoch: 3, batches: 100, num_examples: 6400, 15644.4 samples/sec, epoch time so far: 0:00:00.409091\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:32 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.165 mean_absolute_error: 0.295 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:33 INFO 139898075215680] Epoch: 3, batches: 200, num_examples: 12800, 15816.1 samples/sec, epoch time so far: 0:00:00.809300\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:33 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.162 mean_absolute_error: 0.292 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:33 INFO 139898075215680] Epoch: 3, batches: 300, num_examples: 19200, 15836.1 samples/sec, epoch time so far: 0:00:01.212423\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:33 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.162 mean_absolute_error: 0.293 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:34 INFO 139898075215680] Epoch: 3, batches: 400, num_examples: 25600, 15872.5 samples/sec, epoch time so far: 0:00:01.612857\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:34 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.292 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:34 INFO 139898075215680] Epoch: 3, batches: 500, num_examples: 32000, 15890.1 samples/sec, epoch time so far: 0:00:02.013834\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:34 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.158 mean_absolute_error: 0.291 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:34 INFO 139898075215680] Epoch: 3, batches: 600, num_examples: 38400, 15863.6 samples/sec, epoch time so far: 0:00:02.420634\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:34 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.157 mean_absolute_error: 0.291 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:35 INFO 139898075215680] Epoch: 3, batches: 700, num_examples: 44800, 15879.4 samples/sec, epoch time so far: 0:00:02.821271\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:35 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.156 mean_absolute_error: 0.290 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:35 INFO 139898075215680] Epoch: 3, batches: 800, num_examples: 51200, 15879.0 samples/sec, epoch time so far: 0:00:03.224376\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:35 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.156 mean_absolute_error: 0.292 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/30/2023 06:04:36 INFO 139898075215680] Epoch: 3, batches: 900, num_examples: 57600, 15889.1 samples/sec, epoch time so far: 0:00:03.625121\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:36 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.157 mean_absolute_error: 0.292 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:36 INFO 139898075215680] Epoch: 3, batches: 1000, num_examples: 64000, 15900.6 samples/sec, epoch time so far: 0:00:04.025012\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:36 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.156 mean_absolute_error: 0.292 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:36 INFO 139898075215680] Epoch: 3, batches: 1100, num_examples: 70400, 15908.1 samples/sec, epoch time so far: 0:00:04.425425\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:36 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.155 mean_absolute_error: 0.292 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:37 INFO 139898075215680] Epoch: 3, batches: 1200, num_examples: 76800, 15917.7 samples/sec, epoch time so far: 0:00:04.824805\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:37 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.155 mean_absolute_error: 0.293 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:37 INFO 139898075215680] Epoch: 3, batches: 1300, num_examples: 83200, 15922.3 samples/sec, epoch time so far: 0:00:05.225375\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:37 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.156 mean_absolute_error: 0.293 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] Epoch: 3, batches: 1400, num_examples: 89600, 15926.1 samples/sec, epoch time so far: 0:00:05.625972\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.156 mean_absolute_error: 0.294 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] Completed Epoch: 3, time taken: 0:00:05.694042\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] Epoch 3 Training metrics:   mean_squared_error: 0.155 mean_absolute_error: 0.294 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] #quality_metric: host=algo-1, epoch=3, train mean_squared_error <loss>=0.1554913671587273\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] Epoch 3 Validation metrics: mean_squared_error: 0.957 mean_absolute_error: 0.778 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] #quality_metric: host=algo-1, epoch=3, validation mean_squared_error <loss>=0.9573182592520842\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] patience losses: [0.95061389940816, 0.963320367239617, 0.9449727354017464]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] min patience losses: 0.9449727354017464\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] current loss: 0.9573182592520842\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] absolute loss difference: 0.012345523850337825\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834672.4150972, \"EndTime\": 1682834678.3161044, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.5779266357421875, \"count\": 1, \"min\": 0.5779266357421875, \"max\": 0.5779266357421875}, \"update.time\": {\"sum\": 5889.398813247681, \"count\": 1, \"min\": 5889.398813247681, \"max\": 5889.398813247681}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834672.4266858, \"EndTime\": 1682834678.316429, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 362496.0, \"count\": 1, \"min\": 362496, \"max\": 362496}, \"Total Batches Seen\": {\"sum\": 5664.0, \"count\": 1, \"min\": 5664, \"max\": 5664}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] #throughput_metric: host=algo-1, train throughput=15386.340030189407 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] Epoch: 4, batches: 100, num_examples: 6400, 15950.8 samples/sec, epoch time so far: 0:00:00.401234\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:38 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.106 mean_absolute_error: 0.245 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:39 INFO 139898075215680] Epoch: 4, batches: 200, num_examples: 12800, 15947.3 samples/sec, epoch time so far: 0:00:00.802643\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:39 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.105 mean_absolute_error: 0.244 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:39 INFO 139898075215680] Epoch: 4, batches: 300, num_examples: 19200, 15943.9 samples/sec, epoch time so far: 0:00:01.204221\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:39 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.103 mean_absolute_error: 0.241 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:39 INFO 139898075215680] Epoch: 4, batches: 400, num_examples: 25600, 15953.2 samples/sec, epoch time so far: 0:00:01.604695\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:39 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.103 mean_absolute_error: 0.241 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:40 INFO 139898075215680] Epoch: 4, batches: 500, num_examples: 32000, 15969.7 samples/sec, epoch time so far: 0:00:02.003791\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:40 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.101 mean_absolute_error: 0.240 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:40 INFO 139898075215680] Epoch: 4, batches: 600, num_examples: 38400, 15966.4 samples/sec, epoch time so far: 0:00:02.405045\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:40 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.101 mean_absolute_error: 0.240 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:41 INFO 139898075215680] Epoch: 4, batches: 700, num_examples: 44800, 15970.4 samples/sec, epoch time so far: 0:00:02.805182\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:41 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.100 mean_absolute_error: 0.239 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:41 INFO 139898075215680] Epoch: 4, batches: 800, num_examples: 51200, 15974.4 samples/sec, epoch time so far: 0:00:03.205126\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:41 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.100 mean_absolute_error: 0.239 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:41 INFO 139898075215680] Epoch: 4, batches: 900, num_examples: 57600, 15965.2 samples/sec, epoch time so far: 0:00:03.607844\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:41 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.101 mean_absolute_error: 0.240 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:42 INFO 139898075215680] Epoch: 4, batches: 1000, num_examples: 64000, 15971.0 samples/sec, epoch time so far: 0:00:04.007260\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:42 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.101 mean_absolute_error: 0.240 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:42 INFO 139898075215680] Epoch: 4, batches: 1100, num_examples: 70400, 15968.4 samples/sec, epoch time so far: 0:00:04.408706\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:42 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.100 mean_absolute_error: 0.239 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:43 INFO 139898075215680] Epoch: 4, batches: 1200, num_examples: 76800, 15970.1 samples/sec, epoch time so far: 0:00:04.808988\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:43 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.100 mean_absolute_error: 0.240 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:43 INFO 139898075215680] Epoch: 4, batches: 1300, num_examples: 83200, 15956.3 samples/sec, epoch time so far: 0:00:05.214226\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:43 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.101 mean_absolute_error: 0.240 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:43 INFO 139898075215680] Epoch: 4, batches: 1400, num_examples: 89600, 15957.2 samples/sec, epoch time so far: 0:00:05.615018\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:43 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.101 mean_absolute_error: 0.241 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] Completed Epoch: 4, time taken: 0:00:05.679431\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] Epoch 4 Training metrics:   mean_squared_error: 0.101 mean_absolute_error: 0.241 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] #quality_metric: host=algo-1, epoch=4, train mean_squared_error <loss>=0.10133450045276665\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] Epoch 4 Validation metrics: mean_squared_error: 0.940 mean_absolute_error: 0.767 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] #quality_metric: host=algo-1, epoch=4, validation mean_squared_error <loss>=0.9395079214025188\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] patience losses: [0.963320367239617, 0.9449727354017464, 0.9573182592520842]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] min patience losses: 0.9449727354017464\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] current loss: 0.9395079214025188\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] absolute loss difference: 0.005464813999227602\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834678.3162184, \"EndTime\": 1682834684.1971898, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 4.323005676269531, \"count\": 1, \"min\": 4.323005676269531, \"max\": 4.323005676269531}, \"update.time\": {\"sum\": 5874.013185501099, \"count\": 1, \"min\": 5874.013185501099, \"max\": 5874.013185501099}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834678.3231537, \"EndTime\": 1682834684.1975555, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 453120.0, \"count\": 1, \"min\": 453120, \"max\": 453120}, \"Total Batches Seen\": {\"sum\": 7080.0, \"count\": 1, \"min\": 7080, \"max\": 7080}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] #throughput_metric: host=algo-1, train throughput=15426.553053610824 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] Epoch: 5, batches: 100, num_examples: 6400, 15987.2 samples/sec, epoch time so far: 0:00:00.400321\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:44 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.095 mean_absolute_error: 0.236 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:45 INFO 139898075215680] Epoch: 5, batches: 200, num_examples: 12800, 15960.2 samples/sec, epoch time so far: 0:00:00.801994\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:45 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.092 mean_absolute_error: 0.234 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:45 INFO 139898075215680] Epoch: 5, batches: 300, num_examples: 19200, 15932.5 samples/sec, epoch time so far: 0:00:01.205085\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:45 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.091 mean_absolute_error: 0.232 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:45 INFO 139898075215680] Epoch: 5, batches: 400, num_examples: 25600, 15942.6 samples/sec, epoch time so far: 0:00:01.605761\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:45 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.090 mean_absolute_error: 0.231 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/30/2023 06:04:46 INFO 139898075215680] Epoch: 5, batches: 500, num_examples: 32000, 15919.8 samples/sec, epoch time so far: 0:00:02.010079\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:46 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.090 mean_absolute_error: 0.231 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:46 INFO 139898075215680] Epoch: 5, batches: 600, num_examples: 38400, 15924.5 samples/sec, epoch time so far: 0:00:02.411384\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:46 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.230 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:47 INFO 139898075215680] Epoch: 5, batches: 700, num_examples: 44800, 15917.6 samples/sec, epoch time so far: 0:00:02.814490\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:47 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.230 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:47 INFO 139898075215680] Epoch: 5, batches: 800, num_examples: 51200, 15926.2 samples/sec, epoch time so far: 0:00:03.214820\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:47 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.230 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:47 INFO 139898075215680] Epoch: 5, batches: 900, num_examples: 57600, 15904.3 samples/sec, epoch time so far: 0:00:03.621658\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:47 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:48 INFO 139898075215680] Epoch: 5, batches: 1000, num_examples: 64000, 15911.7 samples/sec, epoch time so far: 0:00:04.022209\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:48 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:48 INFO 139898075215680] Epoch: 5, batches: 1100, num_examples: 70400, 15899.5 samples/sec, epoch time so far: 0:00:04.427825\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:48 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:49 INFO 139898075215680] Epoch: 5, batches: 1200, num_examples: 76800, 15886.3 samples/sec, epoch time so far: 0:00:04.834342\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:49 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:49 INFO 139898075215680] Epoch: 5, batches: 1300, num_examples: 83200, 15897.5 samples/sec, epoch time so far: 0:00:05.233537\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:49 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.230 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:49 INFO 139898075215680] Epoch: 5, batches: 1400, num_examples: 89600, 15901.3 samples/sec, epoch time so far: 0:00:05.634754\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:49 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.230 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:49 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:49 INFO 139898075215680] Completed Epoch: 5, time taken: 0:00:05.698608\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:49 INFO 139898075215680] Epoch 5 Training metrics:   mean_squared_error: 0.089 mean_absolute_error: 0.230 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:49 INFO 139898075215680] #quality_metric: host=algo-1, epoch=5, train mean_squared_error <loss>=0.0885079073940672\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] Epoch 5 Validation metrics: mean_squared_error: 0.945 mean_absolute_error: 0.773 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] #quality_metric: host=algo-1, epoch=5, validation mean_squared_error <loss>=0.9450158263380463\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] patience losses: [0.9449727354017464, 0.9573182592520842, 0.9395079214025188]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] min patience losses: 0.9395079214025188\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] current loss: 0.9450158263380463\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] absolute loss difference: 0.005507904935527441\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834684.1973407, \"EndTime\": 1682834690.1055074, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.6496906280517578, \"count\": 1, \"min\": 0.6496906280517578, \"max\": 0.6496906280517578}, \"update.time\": {\"sum\": 5891.968011856079, \"count\": 1, \"min\": 5891.968011856079, \"max\": 5891.968011856079}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834684.2135098, \"EndTime\": 1682834690.105849, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 543744.0, \"count\": 1, \"min\": 543744, \"max\": 543744}, \"Total Batches Seen\": {\"sum\": 8496.0, \"count\": 1, \"min\": 8496, \"max\": 8496}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] #throughput_metric: host=algo-1, train throughput=15379.483891490701 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] Epoch: 6, batches: 100, num_examples: 6400, 16003.5 samples/sec, epoch time so far: 0:00:00.399913\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.092 mean_absolute_error: 0.233 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] Epoch: 6, batches: 200, num_examples: 12800, 16014.8 samples/sec, epoch time so far: 0:00:00.799259\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:50 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.230 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:51 INFO 139898075215680] Epoch: 6, batches: 300, num_examples: 19200, 16020.9 samples/sec, epoch time so far: 0:00:01.198432\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:51 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:51 INFO 139898075215680] Epoch: 6, batches: 400, num_examples: 25600, 16004.5 samples/sec, epoch time so far: 0:00:01.599553\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:51 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:52 INFO 139898075215680] Epoch: 6, batches: 500, num_examples: 32000, 16010.9 samples/sec, epoch time so far: 0:00:01.998634\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:52 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.085 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:52 INFO 139898075215680] Epoch: 6, batches: 600, num_examples: 38400, 15981.0 samples/sec, epoch time so far: 0:00:02.402849\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:52 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:52 INFO 139898075215680] Epoch: 6, batches: 700, num_examples: 44800, 15968.3 samples/sec, epoch time so far: 0:00:02.805551\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:52 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:53 INFO 139898075215680] Epoch: 6, batches: 800, num_examples: 51200, 15973.2 samples/sec, epoch time so far: 0:00:03.205368\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:53 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.085 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:53 INFO 139898075215680] Epoch: 6, batches: 900, num_examples: 57600, 15952.7 samples/sec, epoch time so far: 0:00:03.610681\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:53 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:54 INFO 139898075215680] Epoch: 6, batches: 1000, num_examples: 64000, 15926.7 samples/sec, epoch time so far: 0:00:04.018411\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:54 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.085 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:54 INFO 139898075215680] Epoch: 6, batches: 1100, num_examples: 70400, 15931.2 samples/sec, epoch time so far: 0:00:04.419014\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:54 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:54 INFO 139898075215680] Epoch: 6, batches: 1200, num_examples: 76800, 15928.6 samples/sec, epoch time so far: 0:00:04.821506\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:54 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.085 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] Epoch: 6, batches: 1300, num_examples: 83200, 15930.8 samples/sec, epoch time so far: 0:00:05.222576\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.085 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] Epoch: 6, batches: 1400, num_examples: 89600, 15938.0 samples/sec, epoch time so far: 0:00:05.621790\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] Completed Epoch: 6, time taken: 0:00:05.687373\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] Epoch 6 Training metrics:   mean_squared_error: 0.086 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] #quality_metric: host=algo-1, epoch=6, train mean_squared_error <loss>=0.08562089269980788\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] Epoch 6 Validation metrics: mean_squared_error: 0.920 mean_absolute_error: 0.754 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] #quality_metric: host=algo-1, epoch=6, validation mean_squared_error <loss>=0.9204286703386823\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] patience losses: [0.9573182592520842, 0.9395079214025188, 0.9450158263380463]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] min patience losses: 0.9395079214025188\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] current loss: 0.9204286703386823\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] absolute loss difference: 0.019079251063836566\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834690.1056275, \"EndTime\": 1682834695.9990785, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 4.190206527709961, \"count\": 1, \"min\": 4.190206527709961, \"max\": 4.190206527709961}, \"update.time\": {\"sum\": 5886.446952819824, \"count\": 1, \"min\": 5886.446952819824, \"max\": 5886.446952819824}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834690.1125996, \"EndTime\": 1682834695.999578, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 634368.0, \"count\": 1, \"min\": 634368, \"max\": 634368}, \"Total Batches Seen\": {\"sum\": 9912.0, \"count\": 1, \"min\": 9912, \"max\": 9912}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:55 INFO 139898075215680] #throughput_metric: host=algo-1, train throughput=15393.388054835112 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:56 INFO 139898075215680] Epoch: 7, batches: 100, num_examples: 6400, 16106.6 samples/sec, epoch time so far: 0:00:00.397352\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:56 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.082 mean_absolute_error: 0.218 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:56 INFO 139898075215680] Epoch: 7, batches: 200, num_examples: 12800, 16011.0 samples/sec, epoch time so far: 0:00:00.799452\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:56 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.079 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:57 INFO 139898075215680] Epoch: 7, batches: 300, num_examples: 19200, 16007.5 samples/sec, epoch time so far: 0:00:01.199440\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:57 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.078 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:57 INFO 139898075215680] Epoch: 7, batches: 400, num_examples: 25600, 16000.8 samples/sec, epoch time so far: 0:00:01.599919\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:57 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.213 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:58 INFO 139898075215680] Epoch: 7, batches: 500, num_examples: 32000, 15961.0 samples/sec, epoch time so far: 0:00:02.004883\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:58 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.076 mean_absolute_error: 0.212 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:58 INFO 139898075215680] Epoch: 7, batches: 600, num_examples: 38400, 15970.1 samples/sec, epoch time so far: 0:00:02.404496\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:58 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.076 mean_absolute_error: 0.211 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:58 INFO 139898075215680] Epoch: 7, batches: 700, num_examples: 44800, 15932.1 samples/sec, epoch time so far: 0:00:02.811929\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:58 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.075 mean_absolute_error: 0.210 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:59 INFO 139898075215680] Epoch: 7, batches: 800, num_examples: 51200, 15917.9 samples/sec, epoch time so far: 0:00:03.216502\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:59 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.074 mean_absolute_error: 0.209 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:59 INFO 139898075215680] Epoch: 7, batches: 900, num_examples: 57600, 15920.5 samples/sec, epoch time so far: 0:00:03.617984\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:04:59 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.074 mean_absolute_error: 0.209 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:00 INFO 139898075215680] Epoch: 7, batches: 1000, num_examples: 64000, 15922.3 samples/sec, epoch time so far: 0:00:04.019525\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:00 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.074 mean_absolute_error: 0.209 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:00 INFO 139898075215680] Epoch: 7, batches: 1100, num_examples: 70400, 15921.0 samples/sec, epoch time so far: 0:00:04.421844\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:00 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.074 mean_absolute_error: 0.209 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:00 INFO 139898075215680] Epoch: 7, batches: 1200, num_examples: 76800, 15933.0 samples/sec, epoch time so far: 0:00:04.820197\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:00 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.074 mean_absolute_error: 0.209 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] Epoch: 7, batches: 1300, num_examples: 83200, 15938.1 samples/sec, epoch time so far: 0:00:05.220195\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.074 mean_absolute_error: 0.210 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] Epoch: 7, batches: 1400, num_examples: 89600, 15905.9 samples/sec, epoch time so far: 0:00:05.633117\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.075 mean_absolute_error: 0.210 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] Completed Epoch: 7, time taken: 0:00:05.719550\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] Epoch 7 Training metrics:   mean_squared_error: 0.075 mean_absolute_error: 0.210 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] #quality_metric: host=algo-1, epoch=7, train mean_squared_error <loss>=0.07460306212042937\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] Epoch 7 Validation metrics: mean_squared_error: 0.921 mean_absolute_error: 0.754 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] #quality_metric: host=algo-1, epoch=7, validation mean_squared_error <loss>=0.9207092592039624\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] patience losses: [0.9395079214025188, 0.9450158263380463, 0.9204286703386823]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] min patience losses: 0.9204286703386823\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] current loss: 0.9207092592039624\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] absolute loss difference: 0.00028058886528015137\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834695.9992478, \"EndTime\": 1682834701.9544327, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.57220458984375, \"count\": 1, \"min\": 0.57220458984375, \"max\": 0.57220458984375}, \"update.time\": {\"sum\": 5939.152240753174, \"count\": 1, \"min\": 5939.152240753174, \"max\": 5939.152240753174}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834696.0152526, \"EndTime\": 1682834701.9548042, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 724992.0, \"count\": 1, \"min\": 724992, \"max\": 724992}, \"Total Batches Seen\": {\"sum\": 11328.0, \"count\": 1, \"min\": 11328, \"max\": 11328}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:01 INFO 139898075215680] #throughput_metric: host=algo-1, train throughput=15257.320593123259 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:02 INFO 139898075215680] Epoch: 8, batches: 100, num_examples: 6400, 15885.6 samples/sec, epoch time so far: 0:00:00.402880\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:02 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.064 mean_absolute_error: 0.193 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:02 INFO 139898075215680] Epoch: 8, batches: 200, num_examples: 12800, 15722.9 samples/sec, epoch time so far: 0:00:00.814097\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:02 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.066 mean_absolute_error: 0.197 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:03 INFO 139898075215680] Epoch: 8, batches: 300, num_examples: 19200, 15282.2 samples/sec, epoch time so far: 0:00:01.256360\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:03 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.195 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:03 INFO 139898075215680] Epoch: 8, batches: 400, num_examples: 25600, 15134.5 samples/sec, epoch time so far: 0:00:01.691501\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:03 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.195 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:04 INFO 139898075215680] Epoch: 8, batches: 500, num_examples: 32000, 14936.8 samples/sec, epoch time so far: 0:00:02.142362\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:04 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.194 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:04 INFO 139898075215680] Epoch: 8, batches: 600, num_examples: 38400, 14975.2 samples/sec, epoch time so far: 0:00:02.564246\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:04 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.194 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:04 INFO 139898075215680] Epoch: 8, batches: 700, num_examples: 44800, 15116.0 samples/sec, epoch time so far: 0:00:02.963753\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:04 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.064 mean_absolute_error: 0.193 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:05 INFO 139898075215680] Epoch: 8, batches: 800, num_examples: 51200, 15224.2 samples/sec, epoch time so far: 0:00:03.363075\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:05 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.064 mean_absolute_error: 0.192 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:05 INFO 139898075215680] Epoch: 8, batches: 900, num_examples: 57600, 15307.1 samples/sec, epoch time so far: 0:00:03.762949\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:05 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.063 mean_absolute_error: 0.192 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/30/2023 06:05:06 INFO 139898075215680] Epoch: 8, batches: 1000, num_examples: 64000, 15379.7 samples/sec, epoch time so far: 0:00:04.161341\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:06 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.063 mean_absolute_error: 0.192 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:06 INFO 139898075215680] Epoch: 8, batches: 1100, num_examples: 70400, 15415.3 samples/sec, epoch time so far: 0:00:04.566890\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:06 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.063 mean_absolute_error: 0.191 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:06 INFO 139898075215680] Epoch: 8, batches: 1200, num_examples: 76800, 15459.1 samples/sec, epoch time so far: 0:00:04.967938\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:06 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.063 mean_absolute_error: 0.191 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] Epoch: 8, batches: 1300, num_examples: 83200, 15506.5 samples/sec, epoch time so far: 0:00:05.365488\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.063 mean_absolute_error: 0.191 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] Epoch: 8, batches: 1400, num_examples: 89600, 15538.7 samples/sec, epoch time so far: 0:00:05.766244\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.063 mean_absolute_error: 0.191 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] Completed Epoch: 8, time taken: 0:00:05.830476\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] Epoch 8 Training metrics:   mean_squared_error: 0.063 mean_absolute_error: 0.191 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] #quality_metric: host=algo-1, epoch=8, train mean_squared_error <loss>=0.06251165866825498\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] Epoch 8 Validation metrics: mean_squared_error: 0.926 mean_absolute_error: 0.765 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] #quality_metric: host=algo-1, epoch=8, validation mean_squared_error <loss>=0.9262216691229794\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] patience losses: [0.9450158263380463, 0.9204286703386823, 0.9207092592039624]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] min patience losses: 0.9204286703386823\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] current loss: 0.9262216691229794\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] absolute loss difference: 0.005792998784297176\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834701.9545288, \"EndTime\": 1682834707.9871805, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.5829334259033203, \"count\": 1, \"min\": 0.5829334259033203, \"max\": 0.5829334259033203}, \"update.time\": {\"sum\": 6025.4175662994385, \"count\": 1, \"min\": 6025.4175662994385, \"max\": 6025.4175662994385}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834701.9617405, \"EndTime\": 1682834707.9874997, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 815616.0, \"count\": 1, \"min\": 815616, \"max\": 815616}, \"Total Batches Seen\": {\"sum\": 12744.0, \"count\": 1, \"min\": 12744, \"max\": 12744}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:07 INFO 139898075215680] #throughput_metric: host=algo-1, train throughput=15039.025648171777 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:08 INFO 139898075215680] Epoch: 9, batches: 100, num_examples: 6400, 16087.0 samples/sec, epoch time so far: 0:00:00.397838\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:08 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.060 mean_absolute_error: 0.187 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:08 INFO 139898075215680] Epoch: 9, batches: 200, num_examples: 12800, 15868.2 samples/sec, epoch time so far: 0:00:00.806647\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:08 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.058 mean_absolute_error: 0.183 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:09 INFO 139898075215680] Epoch: 9, batches: 300, num_examples: 19200, 15858.7 samples/sec, epoch time so far: 0:00:01.210690\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:09 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.058 mean_absolute_error: 0.181 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:09 INFO 139898075215680] Epoch: 9, batches: 400, num_examples: 25600, 15902.5 samples/sec, epoch time so far: 0:00:01.609810\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:09 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.180 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:10 INFO 139898075215680] Epoch: 9, batches: 500, num_examples: 32000, 15899.2 samples/sec, epoch time so far: 0:00:02.012676\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:10 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:10 INFO 139898075215680] Epoch: 9, batches: 600, num_examples: 38400, 15909.4 samples/sec, epoch time so far: 0:00:02.413662\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:10 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:10 INFO 139898075215680] Epoch: 9, batches: 700, num_examples: 44800, 15929.7 samples/sec, epoch time so far: 0:00:02.812365\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:10 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:11 INFO 139898075215680] Epoch: 9, batches: 800, num_examples: 51200, 15931.5 samples/sec, epoch time so far: 0:00:03.213762\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:11 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:11 INFO 139898075215680] Epoch: 9, batches: 900, num_examples: 57600, 15940.9 samples/sec, epoch time so far: 0:00:03.613355\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:11 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:12 INFO 139898075215680] Epoch: 9, batches: 1000, num_examples: 64000, 15922.7 samples/sec, epoch time so far: 0:00:04.019416\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:12 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:12 INFO 139898075215680] Epoch: 9, batches: 1100, num_examples: 70400, 15926.6 samples/sec, epoch time so far: 0:00:04.420281\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:12 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:12 INFO 139898075215680] Epoch: 9, batches: 1200, num_examples: 76800, 15927.5 samples/sec, epoch time so far: 0:00:04.821854\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:12 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] Epoch: 9, batches: 1300, num_examples: 83200, 15933.5 samples/sec, epoch time so far: 0:00:05.221717\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] Epoch: 9, batches: 1400, num_examples: 89600, 15929.6 samples/sec, epoch time so far: 0:00:05.624750\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] Completed Epoch: 9, time taken: 0:00:05.688677\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] Epoch 9 Training metrics:   mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] #quality_metric: host=algo-1, epoch=9, train mean_squared_error <loss>=0.05620746018028276\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] Epoch 9 Validation metrics: mean_squared_error: 0.911 mean_absolute_error: 0.750 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] #quality_metric: host=algo-1, epoch=9, validation mean_squared_error <loss>=0.9112553250145268\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] patience losses: [0.9204286703386823, 0.9207092592039624, 0.9262216691229794]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] min patience losses: 0.9204286703386823\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] current loss: 0.9112553250145268\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] absolute loss difference: 0.00917334532415548\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834707.9873023, \"EndTime\": 1682834713.8776953, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 3.880739212036133, \"count\": 1, \"min\": 3.880739212036133, \"max\": 3.880739212036133}, \"update.time\": {\"sum\": 5883.169651031494, \"count\": 1, \"min\": 5883.169651031494, \"max\": 5883.169651031494}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834707.9945064, \"EndTime\": 1682834713.8780289, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 906240.0, \"count\": 1, \"min\": 906240, \"max\": 906240}, \"Total Batches Seen\": {\"sum\": 14160.0, \"count\": 1, \"min\": 14160, \"max\": 14160}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:13 INFO 139898075215680] #throughput_metric: host=algo-1, train throughput=15402.60864171912 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:14 INFO 139898075215680] Epoch: 10, batches: 100, num_examples: 6400, 15983.0 samples/sec, epoch time so far: 0:00:00.400425\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:14 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.170 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:14 INFO 139898075215680] Epoch: 10, batches: 200, num_examples: 12800, 15955.1 samples/sec, epoch time so far: 0:00:00.802252\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:14 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.170 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:15 INFO 139898075215680] Epoch: 10, batches: 300, num_examples: 19200, 15944.6 samples/sec, epoch time so far: 0:00:01.204173\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:15 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.171 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:15 INFO 139898075215680] Epoch: 10, batches: 400, num_examples: 25600, 15958.5 samples/sec, epoch time so far: 0:00:01.604158\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:15 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.171 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:15 INFO 139898075215680] Epoch: 10, batches: 500, num_examples: 32000, 15956.1 samples/sec, epoch time so far: 0:00:02.005501\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:15 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.171 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-04-30 06:05:28 Uploading - Uploading generated training model\u001b[34m[04/30/2023 06:05:16 INFO 139898075215680] Epoch: 10, batches: 600, num_examples: 38400, 15933.6 samples/sec, epoch time so far: 0:00:02.410007\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:16 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.170 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:16 INFO 139898075215680] Epoch: 10, batches: 700, num_examples: 44800, 15946.3 samples/sec, epoch time so far: 0:00:02.809426\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:16 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.171 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:17 INFO 139898075215680] Epoch: 10, batches: 800, num_examples: 51200, 15943.4 samples/sec, epoch time so far: 0:00:03.211358\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:17 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.171 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:17 INFO 139898075215680] Epoch: 10, batches: 900, num_examples: 57600, 15944.0 samples/sec, epoch time so far: 0:00:03.612651\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:17 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.170 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:17 INFO 139898075215680] Epoch: 10, batches: 1000, num_examples: 64000, 15947.8 samples/sec, epoch time so far: 0:00:04.013103\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:17 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.170 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:18 INFO 139898075215680] Epoch: 10, batches: 1100, num_examples: 70400, 15939.4 samples/sec, epoch time so far: 0:00:04.416739\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:18 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.170 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:18 INFO 139898075215680] Epoch: 10, batches: 1200, num_examples: 76800, 15929.8 samples/sec, epoch time so far: 0:00:04.821143\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:18 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.169 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] Epoch: 10, batches: 1300, num_examples: 83200, 15898.6 samples/sec, epoch time so far: 0:00:05.233168\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.169 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] Epoch: 10, batches: 1400, num_examples: 89600, 15905.1 samples/sec, epoch time so far: 0:00:05.633410\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] #011Training metrics: mean_squared_error: 0.051 mean_absolute_error: 0.169 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] Completed Epoch: 10, time taken: 0:00:05.698432\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] Epoch 10 Training metrics:   mean_squared_error: 0.051 mean_absolute_error: 0.169 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] #quality_metric: host=algo-1, epoch=10, train mean_squared_error <loss>=0.051403018826155764\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] Epoch 10 Validation metrics: mean_squared_error: 0.911 mean_absolute_error: 0.749 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] #quality_metric: host=algo-1, epoch=10, validation mean_squared_error <loss>=0.9114440639276762\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] patience losses: [0.9207092592039624, 0.9262216691229794, 0.9112553250145268]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] min patience losses: 0.9112553250145268\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] current loss: 0.9114440639276762\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] absolute loss difference: 0.00018873891314941105\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] Bad epoch: loss has not improved (enough). Bad count:4\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] Bad epochs exceeded patience. Stopping training early!\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] Early stopping criterion met! Stopping training at epoch: 10\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834713.8778095, \"EndTime\": 1682834719.788324, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.7700920104980469, \"count\": 1, \"min\": 0.7700920104980469, \"max\": 0.7700920104980469}, \"update.time\": {\"sum\": 5894.388914108276, \"count\": 1, \"min\": 5894.388914108276, \"max\": 5894.388914108276}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834713.8939083, \"EndTime\": 1682834719.7887154, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 996864.0, \"count\": 1, \"min\": 996864, \"max\": 996864}, \"Total Batches Seen\": {\"sum\": 15576.0, \"count\": 1, \"min\": 15576, \"max\": 15576}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] #throughput_metric: host=algo-1, train throughput=15373.07467094395 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 WARNING 139898075215680] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] Best model based on epoch 9. Best loss: 0.911\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834719.7884288, \"EndTime\": 1682834719.7918313, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 2.7008056640625, \"count\": 1, \"min\": 2.7008056640625, \"max\": 2.7008056640625}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] Serializing model to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] Saved checkpoint to \"/tmp/tmp0hgbz7vp/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:05:19 INFO 139898075215680] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682834719.7919674, \"EndTime\": 1682834719.8459272, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 52.64902114868164, \"count\": 1, \"min\": 52.64902114868164, \"max\": 52.64902114868164}, \"setuptime\": {\"sum\": 9.200334548950195, \"count\": 1, \"min\": 9.200334548950195, \"max\": 9.200334548950195}, \"totaltime\": {\"sum\": 71582.49139785767, \"count\": 1, \"min\": 71582.49139785767, \"max\": 71582.49139785767}}}\u001b[0m\n",
      "\n",
      "2023-04-30 06:05:39 Completed - Training job completed\n",
      "Training seconds: 322\n",
      "Billable seconds: 322\n"
     ]
    }
   ],
   "source": [
    "## get estimator\n",
    "regressor = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p2.xlarge\",\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "## set hyperparameters\n",
    "regressor.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "## train the model\n",
    "regressor.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that we can upload train (validation) data through the input data channel, and the algorithm will print out train (validation) evaluation metric during training. In addition, the algorithm uses the validation metric to perform early stopping. \n",
    "\n",
    "What if we want to send additional unlabeled data to the algorithm and get predictions from the trained model?\n",
    "This step is called *inference* in the Sagemaker framework. Next, we demonstrate how to use a trained model to perform inference on unseen data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference using trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# create a model using the trained algorithm\n",
    "regression_model = regressor.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: object2vec-2023-04-30-06-06-14-151\n",
      "INFO:sagemaker:Creating endpoint-config with name object2vec-2023-04-30-06-06-14-804\n",
      "INFO:sagemaker:Creating endpoint with name object2vec-2023-04-30-06-06-14-804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "# deploy the model\n",
    "predictor = regression_model.deploy(\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    "    content_type=\"application/json\",\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we send validation data (without labels) to the deployed endpoint for inference. We will see that the resulting prediction error we get from post-training inference matches the best validation error from the training log in the console above (up to floating point error). If you follow the training instruction and parameter setup, you should get mean squared error on the validation set approximately 0.91."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error on validation set is 0.910\n"
     ]
    }
   ],
   "source": [
    "# Send data to the endpoint to get predictions\n",
    "prediction = predictor.predict(valid_r_data)\n",
    "\n",
    "print(\"The mean squared error on validation set is %.3f\" % get_mse_loss(prediction, valid_r_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison against popular libraries\n",
    "\n",
    "Below we provide a chart that compares the performance of *Object2Vec* against several algorithms implemented by popular recommendation system libraries (LibRec https://www.librec.net/ and scikit-surprise http://surpriselib.com/). The error metric we use in the chart is **root mean squared** (RMSE) instead of MSE, so that our result can be compared against the reported results in the aforementioned libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ml-experiment-plot.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation task \n",
    "\n",
    "In this section, we showcase how to use *Object2Vec* to recommend movies, using the binarized rating labels. Here, if a movie rating label for a given user is binarized to `1`, then it means that the movie should be recommended to the user; otherwise, the label is binarized to `0`. The binarized data set is already obtained in the preprocessing section, so we will proceed to apply the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We upload the binarized datasets for classification task to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded data to s3://sagemaker-us-east-1-112573511757/object2vec/movielens/input/recommendation/train/train_c.jsonl\n",
      "Uploaded data to s3://sagemaker-us-east-1-112573511757/object2vec/movielens/input/recommendation/validation/validation_c.jsonl\n"
     ]
    }
   ],
   "source": [
    "for data_name in [\"train\", \"validation\"]:\n",
    "    fname = \"{}_c.jsonl\".format(data_name)\n",
    "    pre_key = os.path.join(input_prefix, \"recommendation\", f\"{data_name}\")\n",
    "    data_path = os.path.join(\"s3://\", bucket, pre_key, fname)\n",
    "    s3_client.upload_file(fname, bucket, os.path.join(pre_key, fname))\n",
    "    input_paths[data_name] = TrainingInput(\n",
    "        data_path, distribution=\"ShardedByS3Key\", content_type=\"application/jsonlines\"\n",
    "    )\n",
    "    print(\"Uploaded data to {}\".format(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already get the algorithm image from the regression task, we can directly start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import s3_input\n",
    "\n",
    "hyperparameters_c = {\n",
    "    \"_kvstore\": \"device\",\n",
    "    \"_num_gpus\": \"auto\",\n",
    "    \"_num_kv_servers\": \"auto\",\n",
    "    \"bucket_width\": 0,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_tolerance\": 0.01,\n",
    "    \"enc0_cnn_filter_width\": 3,\n",
    "    \"enc0_layers\": \"auto\",\n",
    "    \"enc0_max_seq_len\": 1,\n",
    "    \"enc0_network\": \"pooled_embedding\",\n",
    "    \"enc0_token_embedding_dim\": 300,\n",
    "    \"enc0_vocab_size\": 944,\n",
    "    \"enc1_cnn_filter_width\": 3,\n",
    "    \"enc1_layers\": \"auto\",\n",
    "    \"enc1_max_seq_len\": 1,\n",
    "    \"enc1_network\": \"pooled_embedding\",\n",
    "    \"enc1_token_embedding_dim\": 300,\n",
    "    \"enc1_vocab_size\": 1684,\n",
    "    \"enc_dim\": 2048,\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"mini_batch_size\": 2048,\n",
    "    \"mlp_activation\": \"relu\",\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"mlp_layers\": 1,\n",
    "    \"num_classes\": 2,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"output_layer\": \"softmax\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: object2vec-2023-04-30-06-12-23-398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-30 06:12:23 Starting - Starting the training job......\n",
      "2023-04-30 06:12:59 Starting - Preparing the instances for training.........\n",
      "2023-04-30 06:14:37 Downloading - Downloading input data...\n",
      "2023-04-30 06:15:22 Training - Downloading the training image...............\n",
      "2023-04-30 06:17:42 Training - Training image download completed. Training in progress.....\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mNvidia gpu devices, drivers and cuda toolkit versions (only available on hosts with GPU):\u001b[0m\n",
      "\u001b[34mSun Apr 30 06:18:22 2023       \u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34m| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\u001b[0m\n",
      "\u001b[34m|-------------------------------+----------------------+----------------------+\u001b[0m\n",
      "\u001b[34m| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\u001b[0m\n",
      "\u001b[34m| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\u001b[0m\n",
      "\u001b[34m|                               |                      |               MIG M. |\u001b[0m\n",
      "\u001b[34m|===============================+======================+======================|\u001b[0m\n",
      "\u001b[34m|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\u001b[0m\n",
      "\u001b[34m| N/A   42C    P8    25W / 149W |      0MiB / 11441MiB |      0%      Default |\u001b[0m\n",
      "\u001b[34m|                               |                      |                  N/A |\u001b[0m\n",
      "\u001b[34m+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34m| Processes:                                                                  |\u001b[0m\n",
      "\u001b[34m|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\u001b[0m\n",
      "\u001b[34m|        ID   ID                                                   Usage      |\u001b[0m\n",
      "\u001b[34m|=============================================================================|\u001b[0m\n",
      "\u001b[34m|  No running processes found                                                 |\u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34mChecking for nvidia driver and cuda compatibility.\u001b[0m\n",
      "\u001b[34mCUDA Compatibility driver provided.\u001b[0m\n",
      "\u001b[34mProceeding with compatibility check between driver, cuda-toolkit and cuda-compat.\u001b[0m\n",
      "\u001b[34mDetected cuda-toolkit version: 11.1.\u001b[0m\n",
      "\u001b[34mDetected cuda-compat version: 455.32.00.\u001b[0m\n",
      "\u001b[34mDetected Nvidia driver version: 470.57.02.\u001b[0m\n",
      "\u001b[34mNvidia driver compatible with cuda-toolkit. Disabling cuda-compat.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/default-input.json: {'enc_dim': 4096, 'mlp_dim': 512, 'mlp_activation': 'linear', 'mlp_layers': 2, 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': 0.0004, 'mini_batch_size': 32, 'epochs': 30, 'bucket_width': 0, 'early_stopping_tolerance': 0.01, 'early_stopping_patience': 3, 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'hcnn', 'enc1_network': 'enc0', 'enc0_token_embedding_dim': 300, 'enc0_layers': 'auto', 'enc0_cnn_filter_width': 3, 'enc1_token_embedding_dim': 300, 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': 2, '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'auto_gpu'}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'_kvstore': 'device', '_num_gpus': 'auto', '_num_kv_servers': 'auto', 'bucket_width': '0', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.01', 'enc0_cnn_filter_width': '3', 'enc0_layers': 'auto', 'enc0_max_seq_len': '1', 'enc0_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_vocab_size': '944', 'enc1_cnn_filter_width': '3', 'enc1_layers': 'auto', 'enc1_max_seq_len': '1', 'enc1_network': 'pooled_embedding', 'enc1_token_embedding_dim': '300', 'enc1_vocab_size': '1684', 'enc_dim': '2048', 'epochs': '20', 'learning_rate': '0.001', 'mini_batch_size': '2048', 'mlp_activation': 'relu', 'mlp_dim': '1024', 'mlp_layers': '1', 'num_classes': '2', 'optimizer': 'adam', 'output_layer': 'softmax'}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] Final configuration: {'enc_dim': '2048', 'mlp_dim': '1024', 'mlp_activation': 'relu', 'mlp_layers': '1', 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '2048', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': '3', 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc0_max_seq_len': '1', 'enc0_vocab_size': '944', 'enc1_max_seq_len': '1', 'enc1_vocab_size': '1684'}\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] Using default worker.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] Loaded iterator creator application/jsonlines for content type ('application/jsonlines', '1.0')\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] create_iter params {'enc_dim': '2048', 'mlp_dim': '1024', 'mlp_activation': 'relu', 'mlp_layers': '1', 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '2048', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': '3', 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc0_max_seq_len': '1', 'enc0_vocab_size': '944', 'enc1_max_seq_len': '1', 'enc1_vocab_size': '1684'}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] Parameters of encoders: [{'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '944'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '1684'}]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 2048, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 2048, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] Config: {'enc_dim': 2048, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'mlp_dim': 1024, 'mlp_layers': 1, 'output_layer': 'softmax', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': 2, 'epochs': 20, 'mini_batch_size': 2048, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 2048, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 2048, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] use bucketing: False\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:27 INFO 139764300719936] Creating data iterator for /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Source words: 90570\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Target words: 90570\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Total: 90570 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Bucket of (1, 1) : 90570 samples in 45 batches of 2048, approx 2048.0 words/batch\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Replicating 1590 random sentences from bucket (1, 1) to size it to multiple of 2048\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Bucket batch sizes: [BucketBatchSize(batch_size=2048, average_words_per_batch=2048.0)]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] create_iter params {'enc_dim': '2048', 'mlp_dim': '1024', 'mlp_activation': 'relu', 'mlp_layers': '1', 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '2048', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': '3', 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc0_max_seq_len': '1', 'enc0_vocab_size': '944', 'enc1_max_seq_len': '1', 'enc1_vocab_size': '1684'}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Parameters of encoders: [{'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '944'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '1684'}]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 2048, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 2048, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Config: {'enc_dim': 2048, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'mlp_dim': 1024, 'mlp_layers': 1, 'output_layer': 'softmax', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': 2, 'epochs': 20, 'mini_batch_size': 2048, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 2048, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 2048, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] use bucketing: False\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Creating data iterator for /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Source words: 9430\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Target words: 9430\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Total: 9430 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Bucket of (1, 1) : 9430 samples in 5 batches of 2048, approx 2048.0 words/batch\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Replicating 810 random sentences from bucket (1, 1) to size it to multiple of 2048\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Parameters of encoders: [{'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '944'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '1684'}]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 2048, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 2048, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Config: {'enc_dim': 2048, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'mlp_dim': 1024, 'mlp_layers': 1, 'output_layer': 'softmax', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': 2, 'epochs': 20, 'mini_batch_size': 2048, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 2048, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 2048, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Creating new state\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] params {'enc_dim': '2048', 'mlp_dim': '1024', 'mlp_activation': 'relu', 'mlp_layers': '1', 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '2048', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': '3', 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc0_max_seq_len': '1', 'enc0_vocab_size': '944', 'enc1_max_seq_len': '1', 'enc1_vocab_size': '1684', 'default_bucket_key': (1, 1)}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] default_bucket_key (1, 1)\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] nvidia-smi: took 0.032 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] nvidia-smi identified 1 GPUs.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] context [gpu(0)]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Create Store: device\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 WARNING 139764300719936] dense token embedding is used in a multi-gpu setting...consider changing 'token_embedding_storage_type' to 'row_sparse'\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] data_names: ['source', 'target']\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] label_names: ['out_layer_label']\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                                        Output Shape            Param #     Previous Layer                  \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34msource(null)                                        1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_0(Embedding)                                  1x2048                  0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar0(_not_equal_scalar)               1                       0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape0(Reshape)                                   1x1                     0           _not_equal_scalar0              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul0(broadcast_mul)                       1x2048                  0           embed_0                         \n",
      "                                                                                        reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum0(sum)                                           2048                    0           broadcast_mul0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum1(sum)                                           1                       0           reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like0(zeros_like)                             1                       0           sum1                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal0(_equal)                                     1                       0           sum1                            \n",
      "                                                                                        zeros_like0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus0(elemwise_add)                                1                       0           sum1                            \n",
      "                                                                                        _equal0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div0(broadcast_div)                       2048                    0           sum0                            \n",
      "                                                                                        _plus0                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout0(Dropout)                                   2048                    0           broadcast_div0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_1(Embedding)                                  1x2048                  0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar1(_not_equal_scalar)               1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape1(Reshape)                                   1x1                     0           _not_equal_scalar1              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul1(broadcast_mul)                       1x2048                  0           embed_1                         \n",
      "                                                                                        reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum2(sum)                                           2048                    0           broadcast_mul1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum3(sum)                                           1                       0           reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like1(zeros_like)                             1                       0           sum3                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal1(_equal)                                     1                       0           sum3                            \n",
      "                                                                                        zeros_like1                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus1(elemwise_add)                                1                       0           sum3                            \n",
      "                                                                                        _equal1                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div1(broadcast_div)                       2048                    0           sum2                            \n",
      "                                                                                        _plus1                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout1(Dropout)                                   2048                    0           broadcast_div1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_mul0(elemwise_mul)                                 2048                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_minus0(elemwise_sub)                               2048                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mabs0(abs)                                           2048                    0           _minus0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcat0(Concat)                                     8192                    0           _mul0                           \n",
      "                                                                                        dropout0                        \n",
      "                                                                                        dropout1                        \n",
      "                                                                                        abs0                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmlp_fc0(FullyConnected)                             1024                    8389632     concat0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation0(Activation)                             1024                    0           mlp_fc0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout2(Dropout)                                   1024                    0           activation0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34moutput_layer(FullyConnected)                        2                       2050        dropout2                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mout_layer(SoftmaxOutput)                            2                       0           output_layer                    \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 8391682\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] data_shapes [DataDesc[source,(2048, 1),<class 'numpy.float32'>,NTC], DataDesc[target,(2048, 1),<class 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] label_shapes [DataDesc[out_layer_label,(2048,),<class 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] fixed_param_names: []\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:30 INFO 139764300719936] Initialized BucketingPlus Module\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:33 INFO 139764300719936] arg_params keys for module initialization: dict_keys([])\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:33 INFO 139764300719936] all params:dict_keys(['embed_0_weight', 'embed_1_weight', 'mlp_fc0_weight', 'mlp_fc0_bias', 'output_layer_weight', 'output_layer_bias'])\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835507.2561572, \"EndTime\": 1682835513.8955808, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 3319.3089962005615, \"count\": 1, \"min\": 3319.3089962005615, \"max\": 3319.3089962005615}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835513.8957427, \"EndTime\": 1682835513.8958037, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/30/2023 06:18:38 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:38 INFO 139764300719936] Completed Epoch: 0, time taken: 0:00:04.136647\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:38 INFO 139764300719936] Epoch 0 Training metrics:   perplexity: 1.843 cross_entropy: 0.611 accuracy: 0.662 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:38 INFO 139764300719936] #quality_metric: host=algo-1, epoch=0, train cross_entropy <loss>=0.6112393154038324\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:38 INFO 139764300719936] #quality_metric: host=algo-1, epoch=0, train accuracy <score>=0.6623046875\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:38 INFO 139764300719936] Epoch 0 Validation metrics: perplexity: 1.786 cross_entropy: 0.580 accuracy: 0.696 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:38 INFO 139764300719936] #quality_metric: host=algo-1, epoch=0, validation cross_entropy <loss>=0.5800602555274963\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:38 INFO 139764300719936] #quality_metric: host=algo-1, epoch=0, validation accuracy <score>=0.6955078125\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:38 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835513.8956892, \"EndTime\": 1682835518.442588, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"early_stop.time\": {\"sum\": 0.7047653198242188, \"count\": 1, \"min\": 0.7047653198242188, \"max\": 0.7047653198242188}, \"update.time\": {\"sum\": 4257.421016693115, \"count\": 1, \"min\": 4257.421016693115, \"max\": 4257.421016693115}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:38 INFO 139764300719936] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835514.1851354, \"EndTime\": 1682835518.4430094, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Total Batches Seen\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Max Records Seen Between Resets\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Max Batches Seen Between Resets\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Number of Batches Since Last Reset\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:38 INFO 139764300719936] #throughput_metric: host=algo-1, train throughput=21643.54551243101 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:42 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:42 INFO 139764300719936] Completed Epoch: 1, time taken: 0:00:04.141139\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:42 INFO 139764300719936] Epoch 1 Training metrics:   perplexity: 1.720 cross_entropy: 0.542 accuracy: 0.722 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:42 INFO 139764300719936] #quality_metric: host=algo-1, epoch=1, train cross_entropy <loss>=0.5424475934770372\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:42 INFO 139764300719936] #quality_metric: host=algo-1, epoch=1, train accuracy <score>=0.7222113715277778\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:42 INFO 139764300719936] Epoch 1 Validation metrics: perplexity: 1.775 cross_entropy: 0.574 accuracy: 0.699 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:42 INFO 139764300719936] #quality_metric: host=algo-1, epoch=1, validation cross_entropy <loss>=0.5737975239753723\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:42 INFO 139764300719936] #quality_metric: host=algo-1, epoch=1, validation accuracy <score>=0.69931640625\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:42 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835518.442737, \"EndTime\": 1682835522.8246648, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 5.959749221801758, \"count\": 1, \"min\": 5.959749221801758, \"max\": 5.959749221801758}, \"update.time\": {\"sum\": 4264.471530914307, \"count\": 1, \"min\": 4264.471530914307, \"max\": 4264.471530914307}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:42 INFO 139764300719936] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835518.560166, \"EndTime\": 1682835522.8250713, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 184320.0, \"count\": 1, \"min\": 184320, \"max\": 184320}, \"Total Batches Seen\": {\"sum\": 90.0, \"count\": 1, \"min\": 90, \"max\": 90}, \"Max Records Seen Between Resets\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Max Batches Seen Between Resets\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Number of Batches Since Last Reset\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:42 INFO 139764300719936] #throughput_metric: host=algo-1, train throughput=21607.630977870274 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:47 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:47 INFO 139764300719936] Completed Epoch: 2, time taken: 0:00:04.120922\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:47 INFO 139764300719936] Epoch 2 Training metrics:   perplexity: 1.637 cross_entropy: 0.493 accuracy: 0.759 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:47 INFO 139764300719936] #quality_metric: host=algo-1, epoch=2, train cross_entropy <loss>=0.49297446608543394\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:47 INFO 139764300719936] #quality_metric: host=algo-1, epoch=2, train accuracy <score>=0.7592556423611111\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:47 INFO 139764300719936] Epoch 2 Validation metrics: perplexity: 1.835 cross_entropy: 0.607 accuracy: 0.686 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:47 INFO 139764300719936] #quality_metric: host=algo-1, epoch=2, validation cross_entropy <loss>=0.606816577911377\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:47 INFO 139764300719936] #quality_metric: host=algo-1, epoch=2, validation accuracy <score>=0.6859375\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:47 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835522.8248065, \"EndTime\": 1682835527.1279626, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.03457069396972656, \"count\": 1, \"min\": 0.03457069396972656, \"max\": 0.03457069396972656}, \"update.time\": {\"sum\": 4237.126588821411, \"count\": 1, \"min\": 4237.126588821411, \"max\": 4237.126588821411}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:47 INFO 139764300719936] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835522.890805, \"EndTime\": 1682835527.1282656, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 276480.0, \"count\": 1, \"min\": 276480, \"max\": 276480}, \"Total Batches Seen\": {\"sum\": 135.0, \"count\": 1, \"min\": 135, \"max\": 135}, \"Max Records Seen Between Resets\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Max Batches Seen Between Resets\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Number of Batches Since Last Reset\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:47 INFO 139764300719936] #throughput_metric: host=algo-1, train throughput=21747.653544497876 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] Completed Epoch: 3, time taken: 0:00:04.131117\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] Epoch 3 Training metrics:   perplexity: 1.329 cross_entropy: 0.285 accuracy: 0.888 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] #quality_metric: host=algo-1, epoch=3, train cross_entropy <loss>=0.28479962481392757\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] #quality_metric: host=algo-1, epoch=3, train accuracy <score>=0.8880967881944445\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] Epoch 3 Validation metrics: perplexity: 2.196 cross_entropy: 0.786 accuracy: 0.670 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] #quality_metric: host=algo-1, epoch=3, validation cross_entropy <loss>=0.7864567995071411\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] #quality_metric: host=algo-1, epoch=3, validation accuracy <score>=0.6703125\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] patience losses: [0.5800602555274963, 0.5737975239753723, 0.606816577911377]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] min patience losses: 0.5737975239753723\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] current loss: 0.7864567995071411\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] absolute loss difference: 0.21265927553176878\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835527.1280468, \"EndTime\": 1682835531.3834877, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.5319118499755859, \"count\": 1, \"min\": 0.5319118499755859, \"max\": 0.5319118499755859}, \"update.time\": {\"sum\": 4249.722242355347, \"count\": 1, \"min\": 4249.722242355347, \"max\": 4249.722242355347}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835527.1337485, \"EndTime\": 1682835531.3837945, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 368640.0, \"count\": 1, \"min\": 368640, \"max\": 368640}, \"Total Batches Seen\": {\"sum\": 180.0, \"count\": 1, \"min\": 180, \"max\": 180}, \"Max Records Seen Between Resets\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Max Batches Seen Between Resets\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Number of Batches Since Last Reset\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:51 INFO 139764300719936] #throughput_metric: host=algo-1, train throughput=21683.451764792862 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] Completed Epoch: 4, time taken: 0:00:04.131288\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] Epoch 4 Training metrics:   perplexity: 1.065 cross_entropy: 0.063 accuracy: 0.985 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] #quality_metric: host=algo-1, epoch=4, train cross_entropy <loss>=0.06343644774622387\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] #quality_metric: host=algo-1, epoch=4, train accuracy <score>=0.9848198784722222\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] Epoch 4 Validation metrics: perplexity: 2.575 cross_entropy: 0.946 accuracy: 0.696 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] #quality_metric: host=algo-1, epoch=4, validation cross_entropy <loss>=0.9457623362541199\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] #quality_metric: host=algo-1, epoch=4, validation accuracy <score>=0.6958984375\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] patience losses: [0.5737975239753723, 0.606816577911377, 0.7864567995071411]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] min patience losses: 0.5737975239753723\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] current loss: 0.9457623362541199\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] absolute loss difference: 0.37196481227874756\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835531.383591, \"EndTime\": 1682835535.638039, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.5571842193603516, \"count\": 1, \"min\": 0.5571842193603516, \"max\": 0.5571842193603516}, \"update.time\": {\"sum\": 4248.787403106689, \"count\": 1, \"min\": 4248.787403106689, \"max\": 4248.787403106689}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835531.389235, \"EndTime\": 1682835535.6383805, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 460800.0, \"count\": 1, \"min\": 460800, \"max\": 460800}, \"Total Batches Seen\": {\"sum\": 225.0, \"count\": 1, \"min\": 225, \"max\": 225}, \"Max Records Seen Between Resets\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Max Batches Seen Between Resets\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Number of Batches Since Last Reset\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:55 INFO 139764300719936] #throughput_metric: host=algo-1, train throughput=21688.390007296286 records/second\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] Completed Epoch: 5, time taken: 0:00:04.140174\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] Epoch 5 Training metrics:   perplexity: 1.011 cross_entropy: 0.011 accuracy: 1.000 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] #quality_metric: host=algo-1, epoch=5, train cross_entropy <loss>=0.010565607363565101\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] #quality_metric: host=algo-1, epoch=5, train accuracy <score>=0.99951171875\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] Epoch 5 Validation metrics: perplexity: 2.815 cross_entropy: 1.035 accuracy: 0.692 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] #quality_metric: host=algo-1, epoch=5, validation cross_entropy <loss>=1.034844732284546\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] #quality_metric: host=algo-1, epoch=5, validation accuracy <score>=0.691796875\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] patience losses: [0.606816577911377, 0.7864567995071411, 0.9457623362541199]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] min patience losses: 0.606816577911377\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] current loss: 1.034844732284546\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] absolute loss difference: 0.428028154373169\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835535.6381433, \"EndTime\": 1682835539.903927, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.5557537078857422, \"count\": 1, \"min\": 0.5557537078857422, \"max\": 0.5557537078857422}, \"update.time\": {\"sum\": 4260.102033615112, \"count\": 1, \"min\": 4260.102033615112, \"max\": 4260.102033615112}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835535.643806, \"EndTime\": 1682835539.9042294, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 552960.0, \"count\": 1, \"min\": 552960, \"max\": 552960}, \"Total Batches Seen\": {\"sum\": 270.0, \"count\": 1, \"min\": 270, \"max\": 270}, \"Max Records Seen Between Resets\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Max Batches Seen Between Resets\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Number of Batches Since Last Reset\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:18:59 INFO 139764300719936] #throughput_metric: host=algo-1, train throughput=21630.89860658012 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] Completed Epoch: 6, time taken: 0:00:04.162668\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] Epoch 6 Training metrics:   perplexity: 1.003 cross_entropy: 0.003 accuracy: 1.000 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] #quality_metric: host=algo-1, epoch=6, train cross_entropy <loss>=0.0027422694308269356\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] #quality_metric: host=algo-1, epoch=6, train accuracy <score>=1.0\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] Epoch 6 Validation metrics: perplexity: 3.009 cross_entropy: 1.102 accuracy: 0.698 \u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] #quality_metric: host=algo-1, epoch=6, validation cross_entropy <loss>=1.1015370845794679\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] #quality_metric: host=algo-1, epoch=6, validation accuracy <score>=0.69833984375\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] **************\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] patience losses: [0.7864567995071411, 0.9457623362541199, 1.034844732284546]\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] min patience losses: 0.7864567995071411\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] current loss: 1.1015370845794679\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] absolute loss difference: 0.31508028507232677\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] Bad epoch: loss has not improved (enough). Bad count:4\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] Bad epochs exceeded patience. Stopping training early!\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] Early stopping criterion met! Stopping training at epoch: 6\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835539.9040387, \"EndTime\": 1682835544.1919887, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.7791519165039062, \"count\": 1, \"min\": 0.7791519165039062, \"max\": 0.7791519165039062}, \"update.time\": {\"sum\": 4280.050754547119, \"count\": 1, \"min\": 4280.050754547119, \"max\": 4280.050754547119}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835539.9119155, \"EndTime\": 1682835544.1923785, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 645120.0, \"count\": 1, \"min\": 645120, \"max\": 645120}, \"Total Batches Seen\": {\"sum\": 315.0, \"count\": 1, \"min\": 315, \"max\": 315}, \"Max Records Seen Between Resets\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Max Batches Seen Between Resets\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 92160.0, \"count\": 1, \"min\": 92160, \"max\": 92160}, \"Number of Batches Since Last Reset\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] #throughput_metric: host=algo-1, train throughput=21529.49748194026 records/second\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 WARNING 139764300719936] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] Best model based on epoch 1. Best loss: 0.574\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835544.1920996, \"EndTime\": 1682835544.193923, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 1.1169910430908203, \"count\": 1, \"min\": 1.1169910430908203, \"max\": 1.1169910430908203}}}\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] Serializing model to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] Saved checkpoint to \"/tmp/tmpjknqbkdy/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[04/30/2023 06:19:04 INFO 139764300719936] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682835544.193991, \"EndTime\": 1682835544.393698, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 195.53208351135254, \"count\": 1, \"min\": 195.53208351135254, \"max\": 195.53208351135254}, \"setuptime\": {\"sum\": 9.73367691040039, \"count\": 1, \"min\": 9.73367691040039, \"max\": 9.73367691040039}, \"totaltime\": {\"sum\": 37161.03720664978, \"count\": 1, \"min\": 37161.03720664978, \"max\": 37161.03720664978}}}\u001b[0m\n",
      "\n",
      "2023-04-30 06:19:29 Uploading - Uploading generated training model\n",
      "2023-04-30 06:19:29 Completed - Training job completed\n",
      "Training seconds: 293\n",
      "Billable seconds: 293\n"
     ]
    }
   ],
   "source": [
    "## get estimator\n",
    "classifier = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p2.xlarge\",\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "## set hyperparameters\n",
    "classifier.set_hyperparameters(**hyperparameters_c)\n",
    "\n",
    "## train, tune, and test the model\n",
    "classifier.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can create, deploy, and validate the model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: object2vec-2023-04-30-06-19-42-298\n",
      "INFO:sagemaker:Creating endpoint-config with name object2vec-2023-04-30-06-19-42-848\n",
      "INFO:sagemaker:Creating endpoint with name object2vec-2023-04-30-06-19-42-848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "classification_model = classifier.create_model()\n",
    "\n",
    "predictor_2 = classification_model.deploy(\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    "    content_type=\"application/json\",\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_c_data, valid_c_label = data_list_to_inference_format(\n",
    "    copy.deepcopy(validation_data_list), label_thres=3, binarize=True\n",
    ")\n",
    "predictions = predictor_2.predict(valid_c_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the binarized validation set is 0.701\n"
     ]
    }
   ],
   "source": [
    "def get_class_accuracy(res, labels, thres):\n",
    "    if type(res) is dict:\n",
    "        res = res[\"predictions\"]\n",
    "    assert len(res) == len(labels), \"result and label length mismatch!\"\n",
    "    accuracy = 0\n",
    "    for row, label in zip(res, labels):\n",
    "        if type(row) is dict:\n",
    "            if row[\"scores\"][1] > thres:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = 0\n",
    "            if label > thres:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            accuracy += 1 - (prediction - label) ** 2\n",
    "    return accuracy / float(len(res))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"The accuracy on the binarized validation set is %.3f\"\n",
    "    % get_class_accuracy(predictions, valid_c_label, 0.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on validation set you would get should be approximately 0.704."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie retrieval in the embedding space\n",
    "\n",
    "Since *Object2Vec* transforms user and movie ID's into embeddings as part of the training process. After training, it obtains user and movie embeddings in the left and right encoders, respectively. Intuitively, the embeddings should be tuned by the algorithm in a way that facilitates the supervised learning task: since for a specific user, similar movies should have similar ratings, we expect that similar movies should be **close-by** in the embedding space.\n",
    "\n",
    "In this section, we demonstrate how to find the nearest-neighbor (in Euclidean distance) of a given movie ID, among all movie ID's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_embedding_dict(movie_ids, trained_model):\n",
    "    input_instances = list()\n",
    "    for s_id in movie_ids:\n",
    "        input_instances.append({\"in1\": [s_id]})\n",
    "    data = {\"instances\": input_instances}\n",
    "    movie_embeddings = trained_model.predict(data)\n",
    "    embedding_dict = {}\n",
    "    for s_id, row in zip(movie_ids, movie_embeddings[\"predictions\"]):\n",
    "        embedding_dict[s_id] = np.array(row[\"embeddings\"])\n",
    "    return embedding_dict\n",
    "\n",
    "\n",
    "def load_movie_id_name_map(item_file):\n",
    "    movieID_name_map = {}\n",
    "    with open(item_file, \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "        for row in f.readlines():\n",
    "            row = row.strip()\n",
    "            split = row.split(\"|\")\n",
    "            movie_id = split[0]\n",
    "            movie_name = split[1]\n",
    "            sparse_tags = split[-19:]\n",
    "            movieID_name_map[int(movie_id)] = movie_name\n",
    "    return movieID_name_map\n",
    "\n",
    "\n",
    "def get_nn_of_movie(movie_id, candidate_movie_ids, embedding_dict):\n",
    "    movie_emb = embedding_dict[movie_id]\n",
    "    min_dist = float(\"Inf\")\n",
    "    best_id = candidate_movie_ids[0]\n",
    "    for idx, m_id in enumerate(candidate_movie_ids):\n",
    "        candidate_emb = embedding_dict[m_id]\n",
    "        curr_dist = np.linalg.norm(candidate_emb - movie_emb)\n",
    "        if curr_dist < min_dist:\n",
    "            best_id = m_id\n",
    "            min_dist = curr_dist\n",
    "    return best_id, min_dist\n",
    "\n",
    "\n",
    "def get_unique_movie_ids(data_list):\n",
    "    unique_movie_ids = set()\n",
    "    for row in data_list:\n",
    "        unique_movie_ids.add(row[\"in1\"][0])\n",
    "    return list(unique_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = load_csv_data(train_path, \"\\t\", verbose=False)\n",
    "unique_movie_ids = get_unique_movie_ids(train_data_list)\n",
    "embedding_dict = get_movie_embedding_dict(unique_movie_ids, predictor_2)\n",
    "candidate_movie_ids = unique_movie_ids.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the script below, you can check out what is the closest movie to any movie in the data set. Last time we ran it, the closest movie to `Terminator, The (1984)` in the embedding space was `Die Hard (1988)`. Note that, the result will likely differ slightly across different runs of the algorithm, due to randomness in initialization of model parameters.\n",
    "\n",
    "- Just plug in the movie id you want to examine \n",
    "   - For example, the movie ID for Terminator is 195; you can find the movie name and ID pair in the `u.item` file\n",
    "- Note that, the result will likely differ across different runs of the algorithm, due to inherent randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "movie_id_to_examine = 195  # Customize the movie ID you want to examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest movie to Terminator, The (1984) in the embedding space is Deer Hunter, The (1978)\n"
     ]
    }
   ],
   "source": [
    "candidate_movie_ids.remove(movie_id_to_examine)\n",
    "best_id, min_dist = get_nn_of_movie(movie_id_to_examine, candidate_movie_ids, embedding_dict)\n",
    "movieID_name_map = load_movie_id_name_map(\"ml-100k/u.item\")\n",
    "print(\n",
    "    \"The closest movie to {} in the embedding space is {}\".format(\n",
    "        movieID_name_map[movie_id_to_examine], movieID_name_map[best_id]\n",
    "    )\n",
    ")\n",
    "candidate_movie_ids.append(movie_id_to_examine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommended to always delete the endpoints used for hosting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: object2vec-2023-04-30-06-06-14-804\n",
      "INFO:sagemaker:Deleting endpoint with name: object2vec-2023-04-30-06-06-14-804\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: object2vec-2023-04-30-06-19-42-848\n",
      "INFO:sagemaker:Deleting endpoint with name: object2vec-2023-04-30-06-19-42-848\n"
     ]
    }
   ],
   "source": [
    "## clean up\n",
    "predictor.delete_endpoint()\n",
    "predictor_2.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
